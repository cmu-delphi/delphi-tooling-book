# Regression in Tidymodels - Part 2

This chapter is starts off as the Regression in Tidymodels chapter - Epidemiological time series edition and goes from there to making (slightly) more sophisticated predictions and interactive plots.

```{r}
#| echo: false
source("_common.R")
```

## Libraries and data

```{r, message = FALSE}
# Load necessary packages
library(tidymodels)
library(plotly)
```

As a follow-up to the Regression in `Tidymodels` chapter, we're going to look at how the functions we used to perform linear regression fair when applied to a small set of epidemiological time series data. We'll be working with the built-in data on daily confirmed COVID-19 case and death rates for California over Dec. 31, 2020 to Dec. 31, 2021 (this was originally compiled by JHU).

Note that while data is available for all states, we're focusing on just one state's worth of data to avoid having to manage multiple regions (panel data) just yet. 

```{r}
# Load and subset data
ca_case_death_rate_subset <- case_death_rate_subset %>% 
  filter(geo_value == "ca")
```

## Simple linear regression

Our goal for this exercise is to construct a simple linear regression model of daily death rate as a function of daily case rate. And to do this, we'll essentially work through the same routine that we went through above (just in a different scenario). Thus, we'll opt for the same linear regression model specification. As we mentioned previously, setting the mode is unnecessary for linear regression, so let's drop that bit this time round. In addition, `lm` is the default engine for linear regression, so, we don't have to include that bit either.

```{r, echo = FALSE, out.width = "50%", fig.align='center'}
knitr::include_graphics("img/set_engine.png")
```

```{r}
lm_spec_way2 <- linear_reg() 
```

Now we fit our model by inputting the formula (of the form `y ~ x`) `death_rate ~ case_rate` and the `ca_case_death_rate_subset` into the `fit()` function.

```{r}
ca_lm_fit <- lm_spec_way2 %>%
  fit(death_rate ~ case_rate, data = ca_case_death_rate_subset)
ca_lm_fit
```

As before, let's use `purrr`â€™s `pluck()` function to access the underlying fit and then pipe that into `summary()` to get a basic synopsis of our model.

```{r}
ca_lm_fit %>% 
  pluck("fit") %>%
  summary()
```

Now let's forge ahead and get some predictions for the existing dataset. 

```{r}
predict(ca_lm_fit, new_data = ca_case_death_rate_subset)
```

And to get a side-by-side view of the observed and predicted values (which sets us up well to compare them), we'll use `augment()`.

```{r}
# adjoin the model predictions to `ca_case_death_rate_subset`).
augment(ca_lm_fit, new_data = ca_case_death_rate_subset) %>% 
  select(death_rate, .pred)
```

All in all, everything that we did before seems to translate seamlessly over to handling a bit of epidemiological time series data. But realistically, if we're tasked with predicting COVID-19 deaths, do we only want to look to the concurrent (same-day) case information? Or should we look into the past as well? Since what happened in the past can inform us where things are heading, we could also include case rates and death rates as predictors.

## Adding lagged predictors and predicting a sliver of the future

Now the big question is how far back in the past should we look? More specifically, what past case and death rates are most predictive of current deaths. This is a natural question to have at this point, but it ventures into model selection territory which beyond the scope of this article. For those interested, a lagged correlation analysis as described in the [Correlate signals over space and time chapter](correlations.qmd) is one way to start exploring this. So read it if you dare (or if you have the time).

To start, we will add predictors for the lagged 1-day death and case rates as those seem to be perhaps the most sensible choices (because yesterday is generally more predictive of today than two weeks ago would be).

So first, let's add a column for the lagged 1-day death rates by using `dplyr`'s `mutate()` function.

```{r}
ca_subset_wlag <- ca_case_death_rate_subset %>%
  mutate(lag_1_death_rate = lag(death_rate, 1))
```

Then, we can go ahead and create our recipe, and we can add a `lag_1_day_case_rate` column in the same way as we added a non-linear transformation of a predictor before, by using `step_mutate()` on the predictor that's been specified in the recipe formula.

```{r}
rec_spec_lag <- recipe(death_rate ~ case_rate + lag_1_death_rate, data = ca_subset_wlag) %>%
  step_mutate(lag_1_case_rate = lag(case_rate, 1))
```

Now, we just pop the model and recipe into our workflow and then fit the model to our dataset in the same way as we did before.

```{r}
lm_wf_lag <- workflow() %>%
  add_model(lm_spec_way2) %>%
  add_recipe(rec_spec_lag)

ca_lm_fit_lag <- lm_wf_lag %>% fit(ca_subset_wlag)
ca_lm_fit_lag
```

And viola, we got ourselves a trained workflow - which to be clear has undergone both pre-processing (`step_mutate` to add the 1-day lagged case rate as a predictor) and model fitting. 

Now we'll try to use our model to predict the death rate for a day beyond the last in the dataset (so our target date is Jan. 1, 2022). Suppose that a reliable source tells us that the case rate for that day is 84.7 (cases per 100,000 population). From the last row of our dataset, we can see that the lagged 1-day case rate is about 84.4 and the lagged death rate is about 0.142 (deaths per 100,000 population). So we'll throw this info. in a short dataframe and feed it into `new_data`.

```{r}
last_row_ca <- ca_case_death_rate_subset %>% tail(n = 1)

predict(ca_lm_fit_lag, new_data = data.frame(case_rate = 84.7, 
                                             lag_1_death_rate = last_row_ca$death_rate, 
                                             lag_1_case_rate = last_row_ca$case_rate))
```

Hold up... Why is our prediction NA? We inputted the necessary data with the correct variable names (no typos there). So what went wrong? The answer is two paragraphs above. And here it is: Recall that we used `step_mutate` to dynamically add the lagged case rate variable as a predictor. It was not part of the original model specification. So this means that we do not want to designate a variable `lag_1_case_rate`, rather we just need enough rows of data in `new_data` so that when it undergoes the pre-processing step, that step can reach back to grab the lagged 1-day case rate from the `case_rate` variable. This is a bit of a pain, but so be it. The quick and dirty fix is to simply change `n = 1` to 2 in `tail()`, but let's flex our skills with `bind_rows()` instead.

```{r}
# Add new row of to ca_case_death_rate_subset
ca_subset_plus_row <- bind_rows(
  ca_case_death_rate_subset,
  data.frame(geo_value = "ca", 
             time_value = as.Date("2022-01-01"), 
             case_rate = 84.7, 
             lag_1_death_rate = last_row_ca$death_rate)
)
```

And then pop that into predict...

```{r}
predict(ca_lm_fit_lag, new_data = ca_subset_plus_row) %>%
  tail(n = 1)
```

Wonderful. We got ourselves a prediction. But that was a heck of a lot of work to get here. How could we simplify things for ourselves? Well there's a couple things that `epipredict` offers that could help us out here. 

### Option 1 - manually create our own `epi_recipe`

Instead of using a plain old recipe, it is more advantageous to use an `epi_recipe` on an `epi_df`. Why? It unlocks a number of features specific to epidemiological data such as tailored pre-processing steps like creating columns of lagged data. So, instead of using the `mutate()` and `step_mutate()` combo above to get the lagged case and death rate variables, we can simply write the following where we use `step_epi_lag` to lag the predictors and specify how far ahead we want to predict the outcome using `step_epi_ahead`.

```{r}
ca_epi_r <- epi_recipe(ca_case_death_rate_subset) %>%
  step_epi_lag(case_rate, lag = c(0, 1)) %>% 
  step_epi_lag(death_rate, lag = 1) %>% 
  step_epi_ahead(death_rate, ahead = 0)
```

Then, just throw the `epi_recipe` into an `epi_workflow()`, fit the linear model, and predict in the same way as before.

```{r}
ca_epi_wf <- epi_workflow(ca_epi_r, lm_spec_way2) %>%
  fit(ca_case_death_rate_subset)

predict(ca_epi_wf, ca_subset_plus_row %>% select(-lag_1_death_rate)) %>% 
  filter(time_value == "2022-01-01")
```

Notice we get the same prediction as before, just as we'd expect.

### Option 2 - let the `arx_forecaster()` do the work for us

We can take things a notch further because the `epipredict` package has the `arx_forecaster()` function to make our lives easier by pre-processing, training the model, predicting, and performing some basic post-processing, all in one go. The reason why we can use this model is that the above is a technically a type of autoregressive (AR) model, in which a linear combination of previous values are use forecast the variable of interest. In contrast, in a multiple linear regression model, we use a linear combination of predictors to forecast the variable we're interested in.

```{r, warning = FALSE}
ca_arx_pred_jan_22 <- arx_forecaster(
  ca_subset_plus_row %>% select(-lag_1_death_rate), 
  outcome = "death_rate", 
  predictors = c("death_rate", "case_rate"),
  args_list = arx_args_list(
    lags = list(death_rate = c(1), case_rate = c(0,1)),
    ahead = 0L
  )
) 
ca_arx_pred_jan_22$predictions
```

We could easily add more lags for the case and death rates into the function . All that we got to do is add a couple of choice numbers to the `lags` argument. This is infinitely preferable to the (longwinded) alternative of adding them one by one to `step_mutate()`. So let's go ahead and try adding various lags for each of case and death rate to `arx_forecaster()`:

```{r, warning = FALSE}
lots_of_lags_ca <- arx_forecaster(
  ca_subset_plus_row %>% select(-lag_1_death_rate), 
  outcome = "death_rate", 
  predictors = c("case_rate", "death_rate"),
  args_list = arx_args_list(
    lags = list(case_rate = c(0, 1, 2, 3, 4, 7), death_rate = c(1, 2, 3, 4, 7)),
    ahead = 0L
  )
) 
lots_of_lags_ca$predictions
```

The other major benefit of the above forecaster is that it is equipped to handle panel data. That means that for our example we could input several other states worth of data, and get a prediction for each state. For example, we can try plugging in the entirety of the original `case_death_rate_subset` and get a prediction of the death rate on Jan. 1, 2022 for each state. 

```{r, warning = FALSE}
all_the_states <- arx_forecaster(
  case_death_rate_subset, 
  outcome = "death_rate", 
  predictors = c("case_rate", "death_rate"),
  args_list = arx_args_list(
    lags = list(c(0, 1, 2, 3, 4, 7), c(1, 2, 3, 4, 7)),
    ahead = 1L
  )
) 
all_the_states$predictions
```

Neat! We'll learn more about this and other forecasters in later chapters.

## Interactive plot of predictions {#sec-interactive-plot}

Let's finish off by producing an interactive `plotly` choropleth map of our above predictions (along with the 90% predictive intervals) to get a sense of how they may be geospatially related.

First we'll ready our data. The key part is the extraction of the quantiles that make up the 90% predictive intervals. These are by default contained inside a distribution (`.pred_distn`) which we must unnest to get to.

```{r}
# Rename df of predictions to shorten up
all_the_states_df <- all_the_states$predictions

# Extract nested quantiles
all_the_states_df <- all_the_states_df %>% 
  mutate(q = nested_quantiles(.pred_distn)) %>% 
  unnest(q) %>%
  pivot_wider(names_from = tau, values_from = q)

```

Then, we simply adapted the "Customize choropleth code" from the [plotly website](https://plotly.com/r/choropleth-maps/) to our data. The major changes are that we specified what we would like to show when we hover (the predictions and the corresponding 90% predictive interval). As well, we modified the trace (a trace is just a layer to add to the plot with its own data and visualization components), so that the predictions determine the colour of the state and the locations are based on the state abbreviations in `geo_value`.

```{r}
#| fig-height: 1.75
#| code-fold: true
# See on hover
all_the_states_df$hover <- with(all_the_states_df, 
                                     paste(toupper(geo_value), "<br>", 
                                           "Pred death rate:", round(.pred, digits = 3), "<br>", 
                                           "90% pred distn:", paste(round(`0.05`, digits = 3), 
                                                                    round(`0.95`, digits = 3), sep = ", ")))

# Give state boundaries a white border
l <- list(color = toRGB("white"), width = 2)

# Specify some map projection/options
g <- list(
  scope = 'usa',
  projection = list(type = 'albers usa'),
  showlakes = TRUE,
  lakecolor = toRGB('white')
)

fig <- plot_geo(all_the_states_df, locationmode = 'USA-states')
fig <- fig %>% add_trace(
    z = ~.pred, text = ~hover, hoverinfo = 'text', locations = ~toupper(geo_value),
    color = ~.pred, colors = 'Purples'
  ) 

# Add titles and such
fig <- fig %>% colorbar(title = "Death rate")
fig <- fig %>% layout(
    title = '2022-01-01 predicted death rate (per 100,000) by state<br>(Hover for breakdown)',
    geo = g
  )

fig

```
Pretty cool for a quick adaptation of existing `plotly` code. 

At this point, it is good to do your own sanity check to make sure that the prediction values shown on the plot match up to those shown in the output (`all_the_states$predictions`) for each state. From our quick inspection, this checks out.

Finally, it's good to consider what modifications we could make to improve the plot... For instance, if we had the true death rates for that date, then we could show these on the same or on another chloropleth map that's side-by-side to this one. We'll leave it to the reader to try such extensions on their own.

## Attribution

This vignette was largely adapted from [Chapter 3 of ISLR tidymodels labs](https://emilhvitfeldt.github.io/ISLR-tidymodels-labs/03-linear-regression.html). 
