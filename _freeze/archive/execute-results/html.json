{
  "hash": "4d2b35f719103c28883f0aeeaf2e3e2b",
  "result": {
    "markdown": "# Work with archive objects and data revisions\n\nIn addition to the `epi_df` data structure, which we have been working with all\nalong in these vignettes, the `epiprocess` package has a companion structure\ncalled `epi_archive`. In comparison to an `epi_df` object, which can be seen as\nstoring a single snapshot of a data set with the most up-to-date signal values\nas of some given time, an `epi_archive` object stores the full version history\nof a data set. Many signals of interest for epidemiological tracking are subject\nto revision (some more than others), and paying attention to data revisions can\nbe important for all sorts of downstream data analysis and modeling tasks.\n\nThis chapter walks through working with `epi_archive` objects and demonstrates\nsome of their key functionality. We'll work with a signal on the percentage of\ndoctor's visits with CLI (COVID-like illness) computed from medical insurance\nclaims, available through the [COVIDcast\nAPI](https://cmu-delphi.github.io/delphi-epidata/api/covidcast.html). This\nsignal is subject to very heavy and regular revision; you can read more about it\non its [API documentation\npage](https://cmu-delphi.github.io/delphi-epidata/api/covidcast-signals/doctor-visits.html). We'll use the offline version stored in `{epidatasets}`.\n\n\n\n\n\n\n## Getting data into `epi_archive` format\n\nAn `epi_archive` object\ncan be constructed from a data frame, data table, or tibble, provided that it\nhas (at least) the following columns:\n\n* `geo_value`: the geographic value associated with each row of measurements.\n* `time_value`: the time value associated with each row of measurements.\n* `version`: the time value specifying the version for each row of measurements.\n  For example, if in a given row the `version` is January 15, 2022 and\n  `time_value` is January 14, 2022, then this row contains the measurements of\n  the data for January 14, 2022 that were available one day later.\n\nAs we can see from the above, the data frame returned by\n`epidatr::covidcast()` has the columns required for the `epi_archive`\nformat, so we use\n`as_epi_archive()` to cast it into `epi_archive` format.[^1]\n\n[^1]: For a discussion of the removal of\nredundant version updates in `as_epi_archive` using compactify, please refer\nto the [compactify vignette](https://cmu-delphi.github.io/epiprocess/articles/compactify.html).\n\n\n\n::: {.cell layout-align=\"center\" hash='archive_cache/html/unnamed-chunk-2_39c5cbdbb56253b327ea66e6ab4e8220'}\n\n```{.r .cell-code}\nx <- archive_cases_dv_subset_dt %>%\n  select(geo_value, time_value, version, percent_cli) %>%\n  as_epi_archive(compactify = TRUE)\n\nclass(x)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> [1] \"epi_archive\" \"R6\"\n```\n:::\n\n```{.r .cell-code}\nprint(x)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> An `epi_archive` object, with metadata:\n#> * geo_type  = state\n#> * time_type = day\n#> ----------\n#> * min time value = 2020-06-01\n#> * max time value = 2021-11-30\n#> * first version with update = 2020-06-02\n#> * last version with update = 2021-12-01\n#> * No clobberable versions\n#> * versions end   = 2021-12-01\n#> ----------\n#> Data archive (stored in DT field): 119316 x 4\n#> Columns in DT: geo_value, time_value, version, percent_cli\n#> ----------\n#> Public R6 methods: initialize, print, as_of, fill_through_version, \n#>                    truncate_versions_after, merge, group_by, slide, clone\n```\n:::\n:::\n\n\nAn `epi_archive` is special kind of class called an R6 class. Its primary field\nis a data table `DT`, which is of class `data.table` (from the `data.table`\npackage), and has columns `geo_value`, `time_value`, `version`, as well as any\nnumber of additional columns.\n\n\n::: {.cell layout-align=\"center\" hash='archive_cache/html/unnamed-chunk-3_99d23f4e3321a367498344c4b6282562'}\n\n```{.r .cell-code}\nclass(x$DT)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> [1] \"data.table\" \"data.frame\"\n```\n:::\n\n```{.r .cell-code}\nhead(x$DT)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>    geo_value time_value    version percent_cli\n#> 1:        ca 2020-06-01 2020-06-02          NA\n#> 2:        ca 2020-06-01 2020-06-06    2.140116\n#> 3:        ca 2020-06-01 2020-06-08    2.140379\n#> 4:        ca 2020-06-01 2020-06-09    2.114430\n#> 5:        ca 2020-06-01 2020-06-10    2.133677\n#> 6:        ca 2020-06-01 2020-06-11    2.197207\n```\n:::\n:::\n\n\nThe variables `geo_value`, `time_value`, `version` serve as **key variables**\nfor the data table, as well as any other specified in the metadata (described\nbelow). There can only be a single row per unique combination of key variables,\nand therefore the key variables are critical for figuring out how to generate a\nsnapshot of data from the archive, as of a given version (also described below).\n   \n\n::: {.cell layout-align=\"center\" hash='archive_cache/html/unnamed-chunk-4_8b3712fe1140194d1eb702521cf15238'}\n\n```{.r .cell-code}\nkey(x$DT)\n```\n\n::: {.cell-output .cell-output-error}\n```\n#> Error in key(x$DT): could not find function \"key\"\n```\n:::\n:::\n\n \nIn general, the last version of each observation is carried forward (LOCF) to\nfill in data between recorded versions. **A word of caution:** R6 objects,\nunlike most other objects in R, have reference semantics. An important\nconsequence of this is that objects are not copied when modified.\n   \n\n::: {.cell layout-align=\"center\" hash='archive_cache/html/unnamed-chunk-5_86ba88485d14cbc7ddf328b75c606b4d'}\n\n```{.r .cell-code}\noriginal_value <- x$DT$percent_cli[1]\ny <- x # This DOES NOT make a copy of x\ny$DT$percent_cli[1] <- 0\nhead(y$DT)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>    geo_value time_value    version percent_cli\n#> 1:        ca 2020-06-01 2020-06-02    0.000000\n#> 2:        ca 2020-06-01 2020-06-06    2.140116\n#> 3:        ca 2020-06-01 2020-06-08    2.140379\n#> 4:        ca 2020-06-01 2020-06-09    2.114430\n#> 5:        ca 2020-06-01 2020-06-10    2.133677\n#> 6:        ca 2020-06-01 2020-06-11    2.197207\n```\n:::\n\n```{.r .cell-code}\nhead(x$DT)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>    geo_value time_value    version percent_cli\n#> 1:        ca 2020-06-01 2020-06-02    0.000000\n#> 2:        ca 2020-06-01 2020-06-06    2.140116\n#> 3:        ca 2020-06-01 2020-06-08    2.140379\n#> 4:        ca 2020-06-01 2020-06-09    2.114430\n#> 5:        ca 2020-06-01 2020-06-10    2.133677\n#> 6:        ca 2020-06-01 2020-06-11    2.197207\n```\n:::\n\n```{.r .cell-code}\nx$DT$percent_cli[1] <- original_value\n```\n:::\n\n\nTo make a copy, we can use the `clone()` method for an R6 class, as in `y <-\nx$clone()`. You can read more about reference semantics in Hadley Wickham's\n[Advanced R](https://adv-r.hadley.nz/r6.html#r6-semantics) book.\n\n## Some details on metadata\n\nThe following pieces of metadata are included as fields in an `epi_archive`\nobject: \n\n* `geo_type`: the type for the geo values.\n* `time_type`: the type for the time values.\n* `additional_metadata`: list of additional metadata for the data archive.\n\nMetadata for an `epi_archive` object `x` can be accessed (and altered) directly,\nas in `x$geo_type` or `x$time_type`, etc. Just like `as_epi_df()`, the function\n`as_epi_archive()` attempts to guess metadata fields when an `epi_archive`\nobject is instantiated, if they are not explicitly specified in the function\ncall (as it did in the case above).\n\n## Producing snapshots in `epi_df` form\n\nA key method of an `epi_archive` class is `as_of()`, which generates a snapshot\nof the archive in `epi_df` format. This represents the most up-to-date values of\nthe signal variables as of a given version. This can be accessed via `x$as_of()`\nfor an `epi_archive` object `x`, but the package also provides a simple wrapper \nfunction `epix_as_of()` since this is likely a more familiar interface for users\nnot familiar with R6 (or object-oriented programming).\n\n\n::: {.cell layout-align=\"center\" hash='archive_cache/html/unnamed-chunk-6_0150335f0031c0eb619a4ab5e1b2b899'}\n\n```{.r .cell-code}\nx_snapshot <- epix_as_of(x, max_version = as.Date(\"2021-06-01\"))\nclass(x_snapshot)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> [1] \"epi_df\"     \"tbl_df\"     \"tbl\"        \"data.frame\"\n```\n:::\n\n```{.r .cell-code}\nx_snapshot\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> An `epi_df` object, 1,460 x 3 with metadata:\n#> * geo_type  = state\n#> * time_type = day\n#> * as_of     = 2021-06-01\n#> \n#> # A tibble: 1,460 × 3\n#>   geo_value time_value percent_cli\n#> * <chr>     <date>           <dbl>\n#> 1 ca        2020-06-01        2.75\n#> 2 ca        2020-06-02        2.57\n#> 3 ca        2020-06-03        2.48\n#> 4 ca        2020-06-04        2.41\n#> 5 ca        2020-06-05        2.57\n#> 6 ca        2020-06-06        2.63\n#> # ℹ 1,454 more rows\n```\n:::\n\n```{.r .cell-code}\nmax(x_snapshot$time_value)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> [1] \"2021-05-31\"\n```\n:::\n\n```{.r .cell-code}\nattributes(x_snapshot)$metadata$as_of\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> [1] \"2021-06-01\"\n```\n:::\n:::\n\n\nWe can see that the max time value in the `epi_df` object `x_snapshot` that was \ngenerated from the archive is May 29, 2021, even though the specified version\ndate was June 1, 2021. From this we can infer that the doctor's visits signal\nwas 2 days latent on June 1. Also, we can see that the metadata in the `epi_df`\nobject has the version date recorded in the `as_of` field.\n\nBy default, using the maximum of the `version` column in the underlying data table in an\n`epi_archive` object itself generates a snapshot of the latest values of signal\nvariables in the entire archive. The `epix_as_of()` function issues a warning in\nthis case, since updates to the current version may still come in at a later \npoint in time, due to various reasons, such as synchronization issues.\n\n\n::: {.cell layout-align=\"center\" hash='archive_cache/html/unnamed-chunk-7_d5f40a899e63f06b4b5411a752857f2a'}\n\n```{.r .cell-code}\nx_latest <- epix_as_of(x, max_version = max(x$DT$version))\n```\n:::\n\n\nBelow, we pull several snapshots from the archive, spaced one month apart. We\noverlay the corresponding signal curves as colored lines, with the version dates\nmarked by dotted vertical lines, and draw the latest curve in black (from the \nlatest snapshot `x_latest` that the archive can provide).\n\n\n::: {.cell layout-align=\"center\" hash='archive_cache/html/unnamed-chunk-8_204613e6af4268fe83f46e1635e0ba9e'}\n\n```{.r .cell-code}\nself_max <- max(x$DT$version)\nversions <- seq(as.Date(\"2020-06-01\"), self_max - 1, by = \"1 month\")\nsnapshots <- map(\n  versions,\n  function(v) {\n    epix_as_of(x, max_version = v) %>% mutate(version = v)\n  }\n) %>%\n  list_rbind() %>%\n  bind_rows(x_latest %>% mutate(version = self_max)) %>%\n  mutate(latest = version == self_max)\n```\n:::\n\n::: {.cell layout-align=\"center\" hash='archive_cache/html/unnamed-chunk-9_abb01f2c77a56adc9b3456f605179f88'}\n\n```{.r .cell-code  code-fold=\"true\"}\nggplot(\n  snapshots %>% filter(!latest),\n  aes(x = time_value, y = percent_cli)\n) +\n  geom_line(aes(color = factor(version)), na.rm = TRUE) +\n  geom_vline(aes(color = factor(version), xintercept = version), lty = 2) +\n  facet_wrap(~geo_value, scales = \"free_y\", ncol = 1) +\n  scale_x_date(minor_breaks = \"month\", date_labels = \"%b %Y\") +\n  scale_color_viridis_d(option = \"A\", end = .9) +\n  labs(x = \"Date\", y = \"% of doctor's visits with CLI\") +\n  theme(legend.position = \"none\") +\n  geom_line(\n    data = snapshots %>% filter(latest),\n    aes(x = time_value, y = percent_cli),\n    inherit.aes = FALSE, color = \"black\", na.rm = TRUE\n  )\n```\n\n::: {.cell-output-display}\n![](archive_files/figure-html/unnamed-chunk-9-1.svg){fig-align='center' width=90%}\n:::\n:::\n\n\nWe can see some interesting and highly nontrivial revision behavior: at some\npoints in time the provisional data snapshots grossly underestimate the latest\ncurve (look in particular at Florida close to the end of 2021), and at others\nthey overestimate it (both states towards the beginning of 2021), though not \nquite as dramatically. Modeling the revision process, which is often called\n*backfill modeling*, is an important statistical problem in it of itself.\n\n\n## Merging `epi_archive` objects \n\nNow we demonstrate how to merge two `epi_archive` objects together, e.g., so\nthat grabbing data from multiple sources as of a particular version can be\nperformed with a single `as_of` call. The `epi_archive` class provides a method\n`merge()` precisely for this purpose. The wrapper function is called\n`epix_merge()`; this wrapper avoids mutating its inputs, while `x$merge` will\nmutate `x`. Below we merge the working `epi_archive` of versioned percentage CLI\nfrom outpatient visits to another one of versioned COVID-19 case reporting data,\nwhich we fetch the from the [COVIDcast\nAPI](https://cmu-delphi.github.io/delphi-epidata/api/covidcast.html/), on the\nrate scale (counts per 100,000 people in the population).\n\nWhen merging archives, unless the archives have identical data release patterns,\n`NA`s can be introduced in the non-key variables for a few reasons:\n- to represent the \"value\" of an observation before its initial release (when we\n  need to pair it with additional observations from the other archive that have\n  been released)\n- to represent the \"value\" of an observation that has no recorded versions at\n  all (in the same sort of situation)\n- if requested via `sync = \"na\"`, to represent potential update data that we do\n  not yet have access to (e.g., due to encountering issues while attempting to\n  download the currently available version data for one of the archives, but not\n  the other).\n\n\n::: {.cell layout-align=\"center\" hash='archive_cache/html/unnamed-chunk-10_f17506759a99a453bf60434e742adfa5'}\n\n```{.r .cell-code}\n# This code is for illustration and doesn't run.\n# The result is saved/loaded in the (hidden) next chunk from `{epidatasets}`\ny <- pub_covidcast(\n  source = \"jhu-csse\",\n  signals = \"confirmed_7dav_incidence_prop\",\n  time_type = \"day\",\n  geo_type = \"state\",\n  time_values = epirange(20200601, 20211201),\n  geo_values = \"ca,fl,ny,tx\",\n  issues = epirange(20200601, 20211201)\n) %>%\n  select(geo_value, time_value, version = issue, case_rate_7d_av = value) %>%\n  as_epi_archive(compactify = TRUE)\n\nx$merge(y, sync = \"locf\", compactify = FALSE)\nprint(x)\nhead(x$DT)\n```\n:::\n\n::: {.cell layout-align=\"center\" hash='archive_cache/html/unnamed-chunk-11_02fcba02d29e69cfaaf1db0683d5eb4c'}\n::: {.cell-output .cell-output-stdout}\n```\n#> An `epi_archive` object, with metadata:\n#> * geo_type  = state\n#> * time_type = day\n#> ----------\n#> * min time value = 2020-06-01\n#> * max time value = 2021-11-30\n#> * first version with update = 2020-06-02\n#> * last version with update = 2021-12-01\n#> * No clobberable versions\n#> * versions end   = 2021-12-01\n#> ----------\n#> Data archive (stored in DT field): 129638 x 5\n#> Columns in DT: geo_value, time_value, version, percent_cli and 1 more columns\n#> ----------\n#> Public R6 methods: initialize, print, as_of, fill_through_version, \n#>                    truncate_versions_after, merge, group_by, slide, clone\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n#>    geo_value time_value    version percent_cli case_rate_7d_av\n#> 1:        ca 2020-06-01 2020-06-02          NA        6.628329\n#> 2:        ca 2020-06-01 2020-06-06    2.140116        6.628329\n#> 3:        ca 2020-06-01 2020-06-07    2.140116        6.628329\n#> 4:        ca 2020-06-01 2020-06-08    2.140379        6.628329\n#> 5:        ca 2020-06-01 2020-06-09    2.114430        6.628329\n#> 6:        ca 2020-06-01 2020-06-10    2.133677        6.628329\n```\n:::\n:::\n\n\nImportantly, see that `x$merge` mutated `x` to hold the result of the merge. We\ncould also have used `xy = epix_merge(x, y)` to avoid mutating `x`. See the\ndocumentation for either for more detailed descriptions of what mutation,\npointer aliasing, and pointer reseating is possible.\n\n## Sliding version-aware computations\n    \n::: {.callout-note}\nTODO: need a simple example here.\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}