{
  "hash": "67c8411020f78b45d3ee55625996d060",
  "result": {
    "markdown": "# Inner workings of the framework\n\n\n\n\n\nUnderneath the hood, the `arx_forecaster()` (and all our canned\nforecasters) creates (and returns) an `epi_workflow`. \nEssentially, this is a big S3 object that wraps up the 4 modular steps \n(preprocessing - postprocessing) described in the last chapter.\n\n1. Preprocessor: make transformations to the data before model training\n2. Trainer: train a model on data, resulting in a fitted model object\n3. Predictor: make predictions, using a fitted model object and processed test data\n4. Postprocessor: manipulate or transform the predictions before returning\n\nLet's investigate how these interact with `{tidymodels}` and why it's important\nto think of forecasting this way. To have something to play with, we'll continue\nto examine the data and an estimated canned corecaster.\n\n\n\n::: {.cell layout-align=\"center\" hash='forecast-framework_cache/html/demo-workflow_38ac956904953873a24c7e4dd0648ab5'}\n\n```{.r .cell-code}\njhu <- case_death_rate_subset %>%\n  filter(time_value >= max(time_value) - 30)\n\nout_gb <- arx_forecaster(\n  jhu, \"death_rate\", c(\"case_rate\", \"death_rate\"),\n  boost_tree(mode = \"regression\", trees = 20)\n)\n```\n:::\n\n\n## Preprocessing\n\nPreprocessing is accomplished through a `recipe` (imagine baking a cake) as \nprovided in the [`{recipes}`](https://recipes.tidymodels.org) package. \nWe've made a few modifications (to handle\npanel data) as well as added some additional options. The recipe gives a\nspecification of how to handle training data. Think of it like a fancified\n`formula` that you would pass to `lm()`: `y ~ x1 + log(x2)`. In general, \nthere are 2 extensions to the `formula` that `{recipes}` handles: \n\n  1. Doing transformations of both training and test data that can always be \n  applied. These are things like taking the log of a variable, leading or \n  lagging, filtering out rows, handling dummy variables, etc.\n  2. Using statistics from the training data to eventually process test data. \n    This is a major benefit of `{recipes}`. It prevents what the tidy team calls\n    \"data leakage\". A simple example is centering a predictor by its mean. We\n    need to store the mean of the predictor from the training data and use that\n    value on the test data rather than accidentally calculating the mean of\n    the test predictor for centering.\n    \nA recipe is processed in 2 steps, first it is \"prepped\". This calculates and\nstores any intermediate statistics necessary for use on the test data. \nThen it is \"baked\"\nresulting in training data ready for passing into a statistical model (like `lm`).\n\nWe have introduced an `epi_recipe`. It's just a `recipe` that knows how to handle\nthe `time_value`, `geo_value`, and any additional keys so that these are available\nwhen necessary.\n\nThe `epi_recipe` from `out_gb` can be extracted from the result:\n\n::: {.cell layout-align=\"center\" hash='forecast-framework_cache/html/unnamed-chunk-2_701136b2c4657141ea38354f5aad0130'}\n\n```{.r .cell-code}\nlibrary(workflows)\nlibrary(recipes)\nextract_recipe(out_gb$epi_workflow)\n```\n:::\n\n::: {.cell layout-align=\"center\" hash='forecast-framework_cache/html/unnamed-chunk-3_7183beb656c33b42c6c5f5d765805857'}\n::: {.cell-output .cell-output-stdout}\n```\n#> \n#> ── Epi Recipe ───────────────────────────────────────────────────────────────\n#> \n#> ── Inputs \n#> Number of variables by role\n#> raw:        2\n#> geo_value:  1\n#> time_value: 1\n#> \n#> ── Training information \n#> Training data contained 1736 data points and no incomplete rows.\n#> \n#> ── Operations \n#> 1. Lagging: case_rate by 0, 7, 14 | Trained\n#> 2. Lagging: death_rate by 0, 7, 14 | Trained\n#> 3. Leading: death_rate by 7 | Trained\n#> 4. • Removing rows with NA values in: lag_0_case_rate, ... | Trained\n#> 5. • Removing rows with NA values in: ahead_7_death_rate | Trained\n#> 6. • # of recent observations per key limited to:: Inf | Trained\n```\n:::\n:::\n\n\n\nThe \"Inputs\" are the original `epi_df` and the \"roles\" that these are assigned.\nNone of these are predictors or outcomes. Those will be created \nby the recipe when it is prepped. The \"Operations\" are the sequence of \ninstructions to create the cake (baked training data).\nHere we create lagged predictors, lead the outcome, and then remove `NA`s.\nSome models like `lm` internally handle `NA`s, but not everything does, so we\ndeal with them explicitly. The code to do this (inside the forecaster) is\n\n\n::: {.cell layout-align=\"center\" hash='forecast-framework_cache/html/unnamed-chunk-4_7b1a5f279cb0216eb98e81324ade71aa'}\n\n```{.r .cell-code}\ner <- epi_recipe(jhu) %>%\n  step_epi_lag(case_rate, death_rate, lag = c(0, 7, 14)) %>%\n  step_epi_ahead(death_rate, ahead = 7) %>%\n  step_epi_naomit()\n```\n:::\n\n\nWhile `{recipes}` provides a function `step_lag()`, it assumes that the data\nhave no breaks in the sequence of `time_values`. This is a bit dangerous, so\nwe avoid that behaviour. Our `lag/ahead` functions also appropriately adjust the\namount of data to avoid accidentally dropping recent predictors from the test\ndata.\n\n## The model specification\n\nUsers familiar with the `{parsnip}` package will have no trouble here.\nBasically, `{parsnip}` unifies the function signature across statistical models.\nFor example, `lm()` \"likes\" to work with formulas, but `glmnet::glmnet()` uses\n`x` and `y` for predictors and response. `{parsnip}` is agnostic. Both of these\ndo \"linear regression\". Above we switched from `lm()` to `xgboost()` without \nany issue despite the fact that these functions couldn't be more different.\n\n\n::: {.cell layout-align=\"center\" hash='forecast-framework_cache/html/unnamed-chunk-5_904b72e53b7ebec817c2ff42657fface'}\n\n```{.r .cell-code}\nlm(\n  formula, data, subset, weights, na.action,\n  method = \"qr\",\n  model = TRUE, x = FALSE, y = FALSE, qr = TRUE, singular.ok = TRUE,\n  contrasts = NULL, offset, ...\n)\n\nxgboost(\n  data = NULL, label = NULL, missing = NA, weight = NULL,\n  params = list(), nrounds, verbose = 1, print_every_n = 1L,\n  early_stopping_rounds = NULL, maximize = NULL, save_period = NULL,\n  save_name = \"xgboost.model\", xgb_model = NULL, callbacks = list(),\n  ...\n)\n```\n:::\n\n\n`{epipredict}` provides a few engines/modules like `flatline()` and \n`quantile_reg()` to power the `flatline_forecaster()` and provide quantile \nregression, but you should be able to use almost any available models\nlisted [here](https://www.tidymodels.org/find/parsnip/).\n\n\nTo estimate (fit) a preprocessed model, one calls `fit()` on the `epi_workflow`.\n\n\n::: {.cell layout-align=\"center\" hash='forecast-framework_cache/html/unnamed-chunk-6_aa2a47d336b8de9c69394816f02e101e'}\n\n```{.r .cell-code}\newf <- epi_workflow(er, linear_reg()) %>% fit(jhu)\n```\n:::\n\n\n## Predicting and Postprocessing (bound together)\n\nTo stretch the metaphor of preparing a cake to its natural limits, we have\ncreated postprocessing functionality called \"frosting\". Much like the recipe,\neach postprocessing operation is a \"layer\" and we \"slather\" these onto our \nbaked cake. To fix ideas, below is the postprocessing `frosting` for \n`arx_forecaster()`\n\n\n::: {.cell layout-align=\"center\" hash='forecast-framework_cache/html/unnamed-chunk-7_de6af11afc0b108fae8b915da6125069'}\n\n```{.r .cell-code}\nextract_frosting(out_gb$epi_workflow)\n```\n:::\n\n::: {.cell layout-align=\"center\" hash='forecast-framework_cache/html/unnamed-chunk-8_f0ba4b4792cb1d279128e0e42125054f'}\n::: {.cell-output .cell-output-stdout}\n```\n#> \n#> ── Frosting ─────────────────────────────────────────────────────────────────\n#> \n#> ── Layers \n#> 1. Creating predictions: \"<calculated>\"\n#> 2. Resampling residuals for predictive quantiles: \"<calculated>\"\n#> quantile_levels 0.05, 0.95\n#> 3. Adding forecast date: \"2021-12-31\"\n#> 4. Adding target date: \"2022-01-07\"\n#> 5. Thresholding predictions: dplyr::starts_with(\".pred\") to [0, Inf)\n```\n:::\n:::\n\n\n\nHere we have 5 layers of frosting. The first generates the forecasts from the test data.\nThe second uses quantiles of the residuals to create distributional\nforecasts. The next two add columns for the date the forecast was made and the\ndate for which it is intended to occur. Because we are predicting rates, they \nshould be non-negative, so the last layer thresholds both predicted values and\nintervals at 0. The code to do this (inside the forecaster) is\n\n\n::: {.cell layout-align=\"center\" hash='forecast-framework_cache/html/unnamed-chunk-9_20344dac94d93271078a00ddd04a0974'}\n\n```{.r .cell-code}\nf <- frosting() %>%\n  layer_predict() %>%\n  layer_residual_quantiles(\n    quantile_levels = c(.01, .025, seq(.05, .95, by = .05), .975, .99),\n    symmetrize = TRUE\n  ) %>%\n  layer_add_forecast_date() %>%\n  layer_add_target_date() %>%\n  layer_threshold(starts_with(\".pred\"))\n```\n:::\n\n\nAt predict time, we add this object onto the `epi_workflow` and call `predict()`\n\n\n::: {.cell layout-align=\"center\" hash='forecast-framework_cache/html/unnamed-chunk-10_1af407921661ddcfded119d9726e1a59'}\n\n```{.r .cell-code}\ntest_data <- get_test_data(er, jhu)\newf %>%\n  add_frosting(f) %>%\n  predict(test_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> An `epi_df` object, 56 x 6 with metadata:\n#> * geo_type  = state\n#> * time_type = day\n#> * as_of     = 2022-05-31 12:08:25\n#> \n#> # A tibble: 56 × 6\n#>   geo_value time_value  .pred         .pred_distn forecast_date target_date\n#> * <chr>     <date>      <dbl>              <dist> <date>        <date>     \n#> 1 ak        2021-12-31 0.355  quantiles(0.36)[23] 2021-12-31    2022-01-07 \n#> 2 al        2021-12-31 0.325  quantiles(0.32)[23] 2021-12-31    2022-01-07 \n#> 3 ar        2021-12-31 0.496   quantiles(0.5)[23] 2021-12-31    2022-01-07 \n#> 4 as        2021-12-31 0.0836 quantiles(0.08)[23] 2021-12-31    2022-01-07 \n#> 5 az        2021-12-31 0.614  quantiles(0.61)[23] 2021-12-31    2022-01-07 \n#> 6 ca        2021-12-31 0.327  quantiles(0.33)[23] 2021-12-31    2022-01-07 \n#> # ℹ 50 more rows\n```\n:::\n:::\n\n\nThe above `get_test_data()` function examines the recipe and ensures that enough\ntest data is available to create the necessary lags and produce a prediction\nfor the desired future time point (after the end of the training data). This mimics\nwhat would happen if `jhu` contained the most recent available historical data and\nwe wanted to actually predict the future. We could have instead used any test data\nthat contained the necessary predictors.\n\n:::{.callout-note}\nIn the predictions above, you'll see a `time_value` column. That's because we \ncould use **any training data**. We happened to use training data corresponding\nto the most recent available, and it's lags. But we could have instead used\nlast week's or we could use the data that arrives next year, or we could use multiple\n`time_values` for multiple locations. This is completely allowed, though not\nnecessarily what you expect.\n\nIn production forecasting, you'd probably reestimate the model and produce new\npredictions whenever new data arrives. This is exactly what all the canned \nforecasters we provide do. So those strip out the `time_value` column.\n\nBut the next most likely procedure would be\nto feed your previously estimated model (without refitting) the new data.\nTo do this, you'd just call `get_test_data()` on that new data. And the \n`time_value` would still be the same as your `forecast_date`.\n\nGetting many forecasts (multiple `time_values`) for each location, is not\nexactly a typical desire in this context. But it's also not unheard of, so\nit is possible (and analogous to standard, non-time series forecasting). \n:::\n\n\n## Conclusion\n\nInternally, we provide some canned forecaster functions to create reasonable forecasts. \nBut ideally, a user could create their own forecasters by building up the \ncomponents we provide. In other chapters, we try to walk through some of these\ncustomizations. \n\nTo illustrate everything above, here is (roughly) the code for the \n`arx_forecaster()` to predict the death rate, 1 week ahead:\n\n\n::: {.cell layout-align=\"center\" hash='forecast-framework_cache/html/unnamed-chunk-11_d45e3276831a1b40877b2251297fbb9d'}\n\n```{.r .cell-code}\nr <- epi_recipe(jhu) %>%\n  step_epi_ahead(death_rate, ahead = 7) %>%\n  step_epi_lag(case_rate, death_rate, lag = c(0, 7, 14)) %>%\n  step_epi_naomit()\n\nlatest <- get_test_data(r, jhu)\n\nf <- frosting() %>%\n  layer_predict() %>%\n  layer_residual_quantiles() %>%\n  layer_add_forecast_date() %>%\n  layer_add_target_date() %>%\n  layer_threshold(starts_with(\".pred\"))\n\neng <- linear_reg()\nwf <- epi_workflow(r, eng, f) %>% fit(jhu)\npreds <- predict(wf, latest)\n```\n:::\n\nThe code for `arx_forecaster()` simply generalizes this, passing along arguments as needed.\n\n\n::: {.cell layout-align=\"center\" hash='forecast-framework_cache/html/unnamed-chunk-12_b7f75d610d9c4f0ced30040e9aa3a481'}\n\n```{.r .cell-code}\npreds\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> An `epi_df` object, 56 x 6 with metadata:\n#> * geo_type  = state\n#> * time_type = day\n#> * as_of     = 2022-05-31 12:08:25\n#> \n#> # A tibble: 56 × 6\n#>   geo_value time_value  .pred        .pred_distn forecast_date target_date\n#> * <chr>     <date>      <dbl>             <dist> <date>        <date>     \n#> 1 ak        2021-12-31 0.355  quantiles(0.36)[2] 2021-12-31    2022-01-07 \n#> 2 al        2021-12-31 0.325  quantiles(0.32)[2] 2021-12-31    2022-01-07 \n#> 3 ar        2021-12-31 0.496   quantiles(0.5)[2] 2021-12-31    2022-01-07 \n#> 4 as        2021-12-31 0.0836  quantiles(0.2)[2] 2021-12-31    2022-01-07 \n#> 5 az        2021-12-31 0.614  quantiles(0.61)[2] 2021-12-31    2022-01-07 \n#> 6 ca        2021-12-31 0.327  quantiles(0.33)[2] 2021-12-31    2022-01-07 \n#> # ℹ 50 more rows\n```\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}