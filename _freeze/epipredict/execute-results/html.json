{
  "hash": "52d3dd47bf1fefc398a4e4137b8a748a",
  "result": {
    "markdown": "# Overview\n\n\n\n\n\nAt a high level, our goal with `{epipredict}` is to make running simple machine learning / statistical forecasters for epidemiology easy. However, this package is extremely extensible, and that is part of its utility. Our hope is that it is easy for users with epidemiology training and some statistics to fit baseline models while still allowing those with more nuanced statistical understanding to create complicated specializations using the same framework.\n\nServing both populations is the main motivation for our efforts, but at the same time, we have tried hard to make it useful.\n\n\n## Canned forecasters\n\nWe provide a set of basic, easy-to-use forecasters that work out of the box: \n\n* Flatline (basic) forecaster \n* Autoregressive forecaster\n* Autoregressive classifier\n* Smooth autoregressive(AR) forecaster\n\nThese forecasters encapsulate a series of operations (including data preprocessing, model fitting and etc.) all in instant one-liners. \nThey are basically alternatives to each other. The main difference is the use of different models. Three forecasters use different regression models and the other one use a classification model. \n\nThe operations within canned forecasters all follow our uniform **framework**.  \nAlthough these one-liners allow a reasonably limited amount of customization, to uncover any serious customization you need more knowledge on our framework explained in @sec-framework. \n\n## Forecasting framework {#sec-framework}\n\nAt its core, `{epipredict}` is a **framework** for creating custom forecasters.\nBy that we mean that we view the process of creating custom forecasters as\na collection of modular components. All of them should be easy to swap out\nor exchange for others, and massive variety should be available by fairly \nsimple modifications through the addition of steps or layers. \nThere are four types of components:\n    \n1. Preprocessor: make transformations to the data before model training\n2. Trainer: train a model on data, resulting in a fitted model object\n3. Predictor: make predictions, using a fitted model object and processed test data\n4. Postprocessor: manipulate or transform the predictions before returning\n    \nUsers familiar with `{tidymodels}` and especially \nthe `{workflows}` package will notice a lot \nof overlap. This is by design, and is in fact a feature. The truth is that\n`{epipredict}` is a wrapper around much that is contained in these packages.\nTherefore, if you want something from this -verse, it should \"just work\" (we hope).\n\nThe reason for the overlap is that `workflows` _already implements_ the first \nthree steps. And it does this very well. However, it is missing the \npostprocessing stage and currently has no plans for such an implementation. \nAnd this feature is important. All forecasters need post-processing. Anything more complicated (which is nearly everything) \nneeds this as well.\n\nThe second omission from `tidymodels` is support for panel data. Besides\nepidemiological data, economics, psychology, sociology, and many other areas\nfrequently deal with data of this type. So the framework of behind `epipredict`\nimplements this. In principle, this has nothing to do with epidemiology, and \none could simply use this package as a solution for the missing functionality in\n`tidymodels`. Again, this should \"just work\" (we hope).\n\nAll of the _panel data_ functionality is implemented through the `epi_df` data type\ndescribed in the previous part. If you have different panel data, just force it\ninto an `epi_df` as described in @sec-additional-keys.\n\n## Why doesn't this package already exist?\n\n-   Parts of it actually DO exist. There's a universe called `tidymodels`. It \nhandles pre-processing, training, and prediction, bound together, through a \npackage called workflows. We built `epipredict` on top of that setup. In this \nway, you CAN use almost everything they provide.\n-   However, workflows doesn't do post-processing to the extent envisioned here.\nAnd nothing in `tidymodels` handles panel data.\n-   The tidy-team doesn't have plans to do either of these things. (We checked).\n-   There are two packages that do time series built on `tidymodels`, but it's \n\"basic\" time series: 1-step AR models, exponential smoothing, STL decomposition,\netc.[^1] \n\n[^1]: Our group has not prioritized these sorts of models for epidemic \nforecasting, but one could also integrate these methods into our framework.\n\n\n## Show me the basics\n\nFor now, we'll just demonstrate one of the \"canned\" forecasters we provide: an autoregressive forecaster with (or without) covariates that _directly_ trains on the response. This is in contrast to a typical \"iterative\" AR model that trains to predict one-step-ahead, and then plugs in the predictions to \"leverage up\" to longer horizons. You saw this function in @sec-local-forecaster, but now we'll explain\nthe arguments a bit more thoroughly. Below, you'll see how to make a number of modifications to this\nforecaster, but understanding the inner workings, and **why** you would want\nsomething like this (as well as how to do elaborate customizations) \nwill be the subject of the rest of this book. \n\nWe'll use some of the same data we've examined earlier and estimate a model jointly across all locations using only the most recent 30 days of data (available\nin the built-in data frame).\n\n\n::: {.cell layout-align=\"center\" hash='epipredict_cache/html/demo-workflow_4eae93c718993ddbd0717507d3cbbfbe'}\n\n```{.r .cell-code}\njhu <- case_death_rate_subset %>%\n  filter(time_value >= max(time_value) - 30)\n\nlibrary(epipredict)\nout <- arx_forecaster(\n  jhu,\n  outcome = \"death_rate\",\n  predictors = c(\"case_rate\", \"death_rate\")\n)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n#> Warning: The forecast_date is less than the most recent update date of the\n#> data.forecast_date = 2021-12-31 while data is from 2022-05-31.\n```\n:::\n:::\n\n\nThis call produces a warning, which we'll ignore for now. But essentially, it's telling us that our data comes from May 2022 but we're trying to do a forecast for January 2022. The result is likely not an accurate measure of real-time forecast performance, because the data has been revised over time. \n\n\n::: {.cell layout-align=\"center\" hash='epipredict_cache/html/unnamed-chunk-2_7b68ec6f4741ca9ebb25c7a13be54061'}\n\n```{.r .cell-code}\nout\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> \n#> ══ A basic forecaster of type ARX Forecaster ════════════════════════════════\n#> \n#> This forecaster was fit on 2023-06-27 10:43:35\n#> \n#> Training data was an `epi_df` with\n#> • Geography: state,\n#> • Time type: day,\n#> • Using data up-to-date as of: 2022-05-31 12:08:25.\n#> \n#> ── Predictions ──────────────────────────────────────────────────────────────\n#> \n#> A total of 56 predictions are available for\n#> • 56 unique geographic regions,\n#> • At forecast dates: 2021-12-31,\n#> • For target dates: 2022-01-07.\n```\n:::\n:::\n\n\nPrinting the S3 object provides a bunch of summary information describing the \noriginal training data used to estimate the model as well as some information\nof what the predictions are for. It contains three main components:\n  \n1. Metadata about the training data and when the forecast was created\n\n::: {.cell layout-align=\"center\" hash='epipredict_cache/html/unnamed-chunk-3_2d86a3bbe62cc3a5e7b6c3e02059257d'}\n\n```{.r .cell-code}\nstr(out$metadata)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> List of 2\n#>  $ training        :List of 3\n#>   ..$ geo_type : chr \"state\"\n#>   ..$ time_type: chr \"day\"\n#>   ..$ as_of    : POSIXct[1:1], format: \"2022-05-31 12:08:25\"\n#>  $ forecast_created: POSIXct[1:1], format: \"2023-06-27 10:43:35\"\n```\n:::\n:::\n\n2. The predictions in a tibble. The columns give the predictions for each location along with additional columns. By default, these are a 90% prediction interval, the `forecast_date` (the date on which the forecast was putatively made) and the `target_date` (the date for which the forecast is being made).\n\n::: {.cell layout-align=\"center\" hash='epipredict_cache/html/unnamed-chunk-4_75eac823f860d76a7dd42bdea9e94ee1'}\n\n```{.r .cell-code}\nout$predictions\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> # A tibble: 56 × 5\n#>   geo_value  .pred         .pred_distn forecast_date target_date\n#>   <chr>      <dbl>              <dist> <date>        <date>     \n#> 1 ak        0.355  [0.05, 0.95]<q-rng> 2021-12-31    2022-01-07 \n#> 2 al        0.325  [0.05, 0.95]<q-rng> 2021-12-31    2022-01-07 \n#> 3 ar        0.496  [0.05, 0.95]<q-rng> 2021-12-31    2022-01-07 \n#> 4 as        0.0836 [0.05, 0.95]<q-rng> 2021-12-31    2022-01-07 \n#> 5 az        0.614  [0.05, 0.95]<q-rng> 2021-12-31    2022-01-07 \n#> 6 ca        0.327  [0.05, 0.95]<q-rng> 2021-12-31    2022-01-07 \n#> # ℹ 50 more rows\n```\n:::\n:::\n\n3. An S3 object of class `epi_workflow`. This object encapsulates all the instructions necessary to create the prediction. More details on this below.\n\n::: {.cell layout-align=\"center\" hash='epipredict_cache/html/unnamed-chunk-5_f9e3ce37b5ca3e9f59bd1977f249b01f'}\n\n```{.r .cell-code}\nout$epi_workflow\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> ══ Epi Workflow [trained] ═══════════════════════════════════════════════════\n#> Preprocessor: Recipe\n#> Model: linear_reg()\n#> Postprocessor: Frosting\n#> \n#> ── Preprocessor ─────────────────────────────────────────────────────────────\n#> 6 Recipe Steps\n#> \n#> • step_epi_lag()\n#> • step_epi_lag()\n#> • step_epi_ahead()\n#> • step_naomit()\n#> • step_naomit()\n#> • step_training_window()\n#> \n#> ── Model ────────────────────────────────────────────────────────────────────\n#> \n#> Call:\n#> stats::lm(formula = ..y ~ ., data = data)\n#> \n#> Coefficients:\n#>       (Intercept)    lag_0_case_rate    lag_7_case_rate   lag_14_case_rate  \n#>         0.0829475          0.0009830          0.0027035         -0.0005651  \n#>  lag_0_death_rate   lag_7_death_rate  lag_14_death_rate  \n#>         0.2466110          0.1964921          0.0752998  \n#> \n#> ── Postprocessor ────────────────────────────────────────────────────────────\n#> 5 Frosting Layers\n#> \n#> • layer_predict()\n#> • layer_residual_quantiles()\n#> • layer_add_forecast_date()\n#> • layer_add_target_date()\n#> • layer_threshold()\n```\n:::\n:::\n\n\nBy default, the forecaster predicts the outcome (`death_rate`) 1-week ahead, \nusing 3 lags of each predictor (`case_rate` and `death_rate`) at 0 (today), \n1 week back and 2 weeks back. The predictors and outcome can be changed \ndirectly. The rest of the defaults are encapsulated into a list of arguments. \nThis list is produced by `arx_args_list()`. \n\n## Simple adjustments\n\nBasic adjustments can be made through the `args_list`.\n\n\n::: {.cell layout-align=\"center\" hash='epipredict_cache/html/differential-lags_6b8588f2553c80d191c85d09836876f9'}\n\n```{.r .cell-code}\nout2week <- arx_forecaster(\n  epi_data = jhu,\n  outcome = \"death_rate\",\n  predictors = c(\"case_rate\", \"death_rate\"),\n  args_list = arx_args_list(\n    lags = list(case_rate = c(0, 1, 2, 3, 7, 14), death_rate = c(0, 7, 14)),\n    ahead = 14\n  )\n)\n```\n:::\n\n\nHere, we've used different lags on the `case_rate` and are now predicting 2 \nweeks ahead. Note that `lags` and `aheads` are in the same units as the \n`time_value` of the `epi_df` used for training (same as the `epi_slide()` \narguments discussed in @sec-sliding). This example also illustrates\na major difficulty with the \"iterative\" versions of AR models. This model \ndoesn't produce forecasts for `case_rate`, and so, would not have data to \n\"plug in\" for the necessary lags.[^2]\n\n[^2]: An obvious fix is to instead use a VAR and predict both, but this would \nlikely increase the variance of the model, and therefore, may lead to less \naccurate forecasts for the variable of interest.\n\n\nAnother property of the basic model is the prediction interval. We describe this in more detail in a coming chapter, but it is easy to request multiple quantiles.\n\n\n::: {.cell layout-align=\"center\" hash='epipredict_cache/html/differential-levels_a9da683d7e7fef5e4cb6288ad9899809'}\n\n```{.r .cell-code}\nout_q <- arx_forecaster(jhu, \"death_rate\", c(\"case_rate\", \"death_rate\"),\n  args_list = arx_args_list(\n    levels = c(.01, .025, seq(.05, .95, by = .05), .975, .99)\n  )\n)\n```\n:::\n\n\nThe column `.pred_dstn` in the `predictions` object is actually a \"distribution\" here parameterized by its quantiles. For this default forecaster, these are created using the quantiles of the residuals of the predictive model (possibly symmetrized). Here, we used 23 quantiles, but one can grab a particular quantile,\n\n\n::: {.cell layout-align=\"center\" hash='epipredict_cache/html/q1_5df8261d92421ead6dd2d77e0a127517'}\n\n```{.r .cell-code}\nhead(quantile(out_q$predictions$.pred_distn, p = .4))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>        40%        40%        40%        40%        40%        40% \n#> 0.30277798 0.27213225 0.44345734 0.03120647 0.56121844 0.27492711\n```\n:::\n:::\n\n\nor extract the entire distribution into a \"long\" `epi_df` with `tau` being the probability and `q` being the value associated to that quantile.\n\n\n::: {.cell layout-align=\"center\" hash='epipredict_cache/html/q2_439cb3bc49eb03d8b4c34070ac5ba21d'}\n\n```{.r .cell-code}\nout_q$predictions %>%\n  # first create a \"nested\" list-column\n  mutate(.pred_distn = nested_quantiles(.pred_distn)) %>%\n  unnest(.pred_distn) # then unnest it\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> # A tibble: 1,288 × 6\n#>   geo_value .pred      q   tau forecast_date target_date\n#>   <chr>     <dbl>  <dbl> <dbl> <date>        <date>     \n#> 1 ak        0.355 0      0.01  2021-12-31    2022-01-07 \n#> 2 ak        0.355 0      0.025 2021-12-31    2022-01-07 \n#> 3 ak        0.355 0.0371 0.05  2021-12-31    2022-01-07 \n#> 4 ak        0.355 0.123  0.1   2021-12-31    2022-01-07 \n#> 5 ak        0.355 0.174  0.15  2021-12-31    2022-01-07 \n#> 6 ak        0.355 0.211  0.2   2021-12-31    2022-01-07 \n#> # ℹ 1,282 more rows\n```\n:::\n:::\n\n\nAdditional simple adjustments to the basic forecaster can be made using the function:\n\n\n::: {.cell layout-align=\"center\" hash='epipredict_cache/html/unnamed-chunk-6_07ecdd97f1e2f61c667029fbe5d0d406'}\n\n```{.r .cell-code}\narx_args_list(\n  lags = c(0L, 7L, 14L), ahead = 7L, n_training = Inf,\n  forecast_date = NULL, target_date = NULL, levels = c(0.05, 0.95),\n  symmetrize = TRUE, nonneg = TRUE, quantile_by_key = \"geo_value\"\n)\n```\n:::\n\n\n## Changing the engine\n\nSo far, our forecasts have been produced using simple linear regression. But this is not the only way to estimate such a model.\nThe `trainer` argument determines the type of model we want. \nThis takes a `{parsnip}` model. The default is linear regression, but we could instead use a random forest with the `{ranger}` package:\n\n\n::: {.cell layout-align=\"center\" hash='epipredict_cache/html/ranger_165b974f4c4580092d3398b1d2bee018'}\n\n```{.r .cell-code}\nout_rf <- arx_forecaster(\n  jhu, \"death_rate\", c(\"case_rate\", \"death_rate\"),\n  rand_forest(mode = \"regression\")\n)\n```\n:::\n\n\nOr boosted regression trees with `{xgboost}`:\n\n\n::: {.cell layout-align=\"center\" hash='epipredict_cache/html/xgboost_59219c946dd5689d23feb924a64c64be'}\n\n```{.r .cell-code}\nout_gb <- arx_forecaster(\n  jhu, \"death_rate\", c(\"case_rate\", \"death_rate\"),\n  boost_tree(mode = \"regression\", trees = 20)\n)\n```\n:::\n\n\nOr quantile regression, using our custom forecasting engine `quantile_reg()`:\n\n\n::: {.cell layout-align=\"center\" hash='epipredict_cache/html/quantreg_4e2d216ee037905d2417be2d184f5664'}\n\n```{.r .cell-code}\nout_gb <- arx_forecaster(\n  jhu, \"death_rate\", c(\"case_rate\", \"death_rate\"),\n  quantile_reg()\n)\n```\n:::\n\n\nFWIW, this last case (using quantile regression), is not far from what the Delphi production forecast team used for its Covid forecasts over the past few years.\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}