{
  "hash": "ff6d7f3fc9125df42623428c443d0442",
  "result": {
    "markdown": "# Examples of Preprocessing and Models\n\n\n::: {.cell}\n\n:::\n\n\n\n## Introduction \n\nThe `epipredict` package uses the `tidymodels` framework, namely \n[`{recipes}`](https://recipes.tidymodels.org/) for \n[dplyr](https://dplyr.tidyverse.org/)-like pipeable sequences \nof feature engineering and [`{parsnip}`](https://parsnip.tidymodels.org/) \nfor a unified interface to a range of models. \n\n`epipredict` has additional customized feature engineering and preprocessing \nsteps that specifically work with panel data in this context, for example,\n`step_epi_lag()`, `step_population_scaling()`, \n`step_epi_naomit()`. They can be used along with most\nsteps from the `{recipes}` package for more feature engineering. \n\nIn this vignette, we will illustrate some examples of how to use `epipredict`\nwith `recipes` and `parsnip` for different purposes of \nepidemiological forecasting.\nWe will focus on basic autoregressive models, in which COVID cases and \ndeaths in the near future are predicted using a linear combination of cases\nand deaths in the near past.\n\nThe remaining vignette will be split into three sections. In the first\nsection, we \nwill use a Poisson regression to predict death counts. In the second section,\nwe will use a linear regression to predict death rates. Last but not least, we\nwill create a classification model for hotspot predictions. \n\n\n::: {.cell layout-align=\"center\" hash='preprocessing-and-models_cache/html/unnamed-chunk-2_addbfa8195f76724bf5d26a47c5098c2'}\n\n```{.r .cell-code}\nlibrary(epidatr)\nlibrary(epipredict)\nlibrary(recipes)\nlibrary(workflows)\nlibrary(poissonreg)\n```\n:::\n\n\n## Poisson Regression \n\nDuring COVID-19, the U.S. Centers for Disease Control and Prevention (CDC) \ncollected models\nand forecasts to characterize the state of an outbreak and its course. They use\nit to inform public health decision makers on potential consequences of \ndeploying control measures.\n\nOne of the outcomes that the CDC forecasts is [death counts from COVID-19](https://www.cdc.gov/coronavirus/2019-ncov/science/forecasting/forecasting-us.html).\nAlthough there are many state-of-the-art models, we choose to use Poisson \nregression, the textbook example for modeling count data, as an illustration\nfor using the `epipredict` package with other existing `{tidymodels}` packages. \n\nThe (folded) code below gives the necessary commands to download this data\nfrom the Delphi Epidata API, but it is also built into the\n[`{epidatasets}`](https://cmu-delphi.github.io/epidatasets/reference/counts_subset.html)\npackage.\n\n\n::: {.cell layout-align=\"center\" hash='preprocessing-and-models_cache/html/poisson-reg-data_c5de04bad991fb8b7f75c6079d291fcc'}\n\n```{.r .cell-code  code-fold=\"true\"}\ngeos <- c(\"ca\", \"fl\", \"tx\", \"ny\", \"nj\")\nx <- pub_covidcast(\n  source = \"jhu-csse\",\n  signals = \"confirmed_incidence_num\",\n  time_type = \"day\",\n  geo_type = \"state\",\n  time_values = epirange(20210604, 20211231),\n  geo_values = geos\n) %>%\n  select(geo_value, time_value, cases = value)\n\ny <- pub_covidcast(\n  source = \"jhu-csse\",\n  signals = \"deaths_incidence_num\",\n  time_type = \"day\",\n  geo_type = \"state\",\n  time_values = epirange(20210604, 20211231),\n  geo_values = geos\n) %>%\n  select(geo_value, time_value, deaths = value)\n\ncounts_subset <- full_join(x, y, by = c(\"geo_value\", \"time_value\")) %>%\n  as_epi_df()\n```\n:::\n\n::: {.cell layout-align=\"center\" hash='preprocessing-and-models_cache/html/unnamed-chunk-3_6ecff77ccdcb29ad29987c08784305d2'}\n\n```{.r .cell-code}\ndata(counts_subset, package = \"epidatasets\")\n```\n:::\n\n\nThe `counts_subset` dataset\ncontains the number of confirmed cases and deaths from June 4, 2021 to \nDec 31, 2021 in some U.S. states. \n\nWe wish to predict the 7-day ahead death counts with lagged cases and deaths.\nFurthermore, we will let each state be a dummy variable. Using differential \nintercept coefficients, we can allow for an intercept shift between states.\n\nOne possible model takes the form\n\\begin{aligned}\n\\log\\left( \\mu_{t+7} \\right) &{}= \\beta_0 + \\delta_1 s_{\\text{state}_1} +\n\\delta_2 s_{\\text{state}_2} + \\cdots +  \\nonumber \\\\ &\\quad\\beta_1 \\text{deaths}_{t} + \n\\beta_2 \\text{deaths}_{t-7}  + \\beta_3 \\text{cases}_{t} + \n\\beta_4 \\text{cases}_{t-7},\n\\end{aligned}\nwhere $\\mu_{t+7} = \\mathbb{E}(\\text{deaths}_{t+7})$, and $\\text{deaths}_{t+7}$\nis assumed to follow a Poisson distribution with mean $\\mu_{t+7}$;\n$s_{\\text{state}}$ are dummy variables for each state and take values of either\n0 or 1.\n\nPreprocessing steps will be performed to prepare the\ndata for model fitting. But before diving into them, it will be helpful to understand what `roles` are in the `recipes` framework. \n\n---\n\n#### Aside on `recipes` {.unnumbered}\n\n`recipes` can assign one or more roles to each column in the data. The roles \nare not restricted to a predefined set; they can be anything. \nFor most conventional situations, they are typically “predictor” and/or \n\"outcome\". Additional roles enable targeted `step_*()` operations on specific \nvariables or groups of variables.\n\nIn our case, the role `predictor` is given to explanatory variables on the\nright-hand side of the model (in the equation above). \nThe role `outcome` is the response variable \nthat we wish to predict. `geo_value` and `time_value` are predefined roles \nthat are unique to the `epipredict` package. Since we work with `epi_df` \nobjects, all datasets should have `geo_value` and `time_value` passed through\nautomatically with these two roles assigned to the appropriate columns in the data.\n \nThe `recipes` package also allows [manual alterations of roles](https://recipes.tidymodels.org/reference/roles.html) \nin bulk. There are a few handy functions that can be used together to help us \nmanipulate variable roles easily. \n\n> `update_role()` alters an existing role in the recipe or assigns an initial role \n> to variables that do not yet have a declared role.\n> \n> `add_role()` adds an additional role to variables that already have a role in \n> the recipe, without overwriting old roles.\n> \n> `remove_role()` eliminates a single existing role in the recipe.\n\n#### End aside {.unnumbered}\n\n---\n\nNotice in the following preprocessing steps, we used `add_role()` on \n`geo_value_factor` since, currently, the default role for it is `raw`, but\nwe would like to reuse this variable as a `predictor`.\n\n\n::: {.cell layout-align=\"center\" hash='preprocessing-and-models_cache/html/unnamed-chunk-4_90b277143c4c937a1680363162df6b8b'}\n\n```{.r .cell-code}\ncounts_subset <- counts_subset %>%\n  mutate(geo_value_factor = as.factor(geo_value)) %>%\n  as_epi_df()\n\nepi_recipe(counts_subset)\n\nr <- epi_recipe(counts_subset) %>%\n  add_role(geo_value_factor, new_role = \"predictor\") %>%\n  step_dummy(geo_value_factor) %>%\n  ## Occasionally, data reporting errors / corrections result in negative\n  ## cases / deaths\n  step_mutate(cases = pmax(cases, 0), deaths = pmax(deaths, 0)) %>%\n  step_epi_lag(cases, deaths, lag = c(0, 7)) %>%\n  step_epi_ahead(deaths, ahead = 7, role = \"outcome\") %>%\n  step_epi_naomit()\n```\n:::\n\n\nAfter specifying the preprocessing steps, we will use the `parsnip` package for\nmodeling and producing the prediction for death count, 7 days after the\nlatest available date in the dataset. \n\n\n::: {.cell layout-align=\"center\" hash='preprocessing-and-models_cache/html/unnamed-chunk-5_343ca6ec29d09be57ab611380fba40c7'}\n\n```{.r .cell-code}\nlatest <- get_test_data(r, counts_subset)\n\nwf <- epi_workflow(r, parsnip::poisson_reg()) %>%\n  fit(counts_subset)\n\npredict(wf, latest) %>% filter(!is.na(.pred))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> An `epi_df` object, 5 x 3 with metadata:\n#> * geo_type  = state\n#> * time_type = day\n#> * as_of     = 2023-06-07 16:52:32\n#> \n#> # A tibble: 5 × 3\n#>   geo_value time_value .pred\n#> * <chr>     <date>     <dbl>\n#> 1 ca        2021-12-31 108. \n#> 2 fl        2021-12-31 270. \n#> 3 nj        2021-12-31  22.5\n#> 4 ny        2021-12-31  94.8\n#> 5 tx        2021-12-31  91.0\n```\n:::\n:::\n\n\nNote that the `time_value` corresponds to the date(s) in the \ntest set `latest`, **NOT** to the target date of the forecast (2022-01-07). Had we used different data for predictions,\nwe would have gotten different `time_value`'s.\n\nLet's take a look at the fit:\n\n::: {.cell layout-align=\"center\" hash='preprocessing-and-models_cache/html/unnamed-chunk-6_31441e0d10c16615d3182594c1fec30f'}\n\n```{.r .cell-code}\nextract_fit_engine(wf)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> \n#> Call:  stats::glm(formula = ..y ~ ., family = stats::poisson, data = data)\n#> \n#> Coefficients:\n#>         (Intercept)  geo_value_factor_fl  geo_value_factor_nj  \n#>           3.970e+00           -1.487e-01           -1.425e+00  \n#> geo_value_factor_ny  geo_value_factor_tx          lag_0_cases  \n#>          -6.865e-01            3.025e-01            1.339e-05  \n#>         lag_7_cases         lag_0_deaths         lag_7_deaths  \n#>           1.717e-06            1.731e-03            8.566e-04  \n#> \n#> Degrees of Freedom: 984 Total (i.e. Null);  976 Residual\n#> Null Deviance:\t    139600 \n#> Residual Deviance: 58110 \tAIC: 62710\n```\n:::\n:::\n\n\nAlternative forms of Poisson regression or particular computational approaches\ncan be applied via arguments to `parsnip::poisson_reg()` for some common\nsettings, and by using `parsnip::set_engine()` to use a specific Poisson\nregression engine and to provide additional engine-specific customization.\n\n\n\n## Linear Regression \n\nFor COVID-19, the CDC required submission of case and death count predictions. \nHowever, the Delphi Group preferred to train on rate data instead, because it \nputs different locations on a similar scale (eliminating the need for location-specific intercepts). \nWe can use a linear regression to predict the death rates and use state\npopulation data to scale the rates to counts.[^pois] We will do so using\n`layer_population_scaling()` from the `epipredict` package. (We could also use\n`step_population_scaling()` from the `epipredict` package to prepare rate data\nfrom count data in the preprocessing recipe.)\n\n[^pois]: We could continue with the Poisson model, but we'll switch to the Gaussian likelihood just for simplicity.\n\nAdditionally, when forecasts are submitted, prediction intervals should be \nprovided along with the point estimates. This can be obtained via postprocessing\nusing\n`layer_residual_quantiles()`. It is worth pointing out, however, that \n`layer_residual_quantiles()` should be used before population scaling or else \nthe transformation will make the results uninterpretable. \n\nWe wish, now, to predict the 7-day ahead death counts with lagged case rates and death\nrates, along with some extra behaviourial predictors. Namely, we will use survey data\nfrom [COVID-19 Trends and Impact Survey](https://cmu-delphi.github.io/delphi-epidata/api/covidcast-signals/fb-survey.html#behavior-indicators).\n\nThe survey data provides the estimated percentage of people who wore a mask for \nmost or all of the time while in public in the past 7 days and the estimated \npercentage of respondents who reported that all or most people they encountered \nin public in the past 7 days maintained a distance of at least 6 feet. \n\n\n::: {.cell layout-align=\"center\" hash='preprocessing-and-models_cache/html/unnamed-chunk-7_fea19afe67d26c42ddc444543855e84a'}\n\n```{.r .cell-code  code-fold=\"true\"}\n# Download the raw data as used in {epidatasets}\nbehav_ind_mask <- pub_covidcast(\n  source = \"fb-survey\",\n  signals = \"smoothed_wwearing_mask_7d\",\n  time_type = \"day\",\n  geo_type = \"state\",\n  time_values = epirange(20210604, 20211231),\n  geo_values = geos\n) %>%\n  select(geo_value, time_value, masking = value)\n\nbehav_ind_distancing <- pub_covidcast(\n  source = \"fb-survey\",\n  signals = \"smoothed_wothers_distanced_public\",\n  time_type = \"day\",\n  geo_type = \"state\",\n  time_values = epirange(20210604, 20211231),\n  geo_values = geos\n) %>%\n  select(geo_value, time_value, distancing = value)\n\nctis_covid_behaviours <- behav_ind_mask %>%\n  full_join(behav_ind_distancing, by = c(\"geo_value\", \"time_value\"))\n```\n:::\n\n::: {.cell layout-align=\"center\" hash='preprocessing-and-models_cache/html/unnamed-chunk-8_dbf1236064e03ae10b6694621ce91509'}\n\n```{.r .cell-code}\ndata(ctis_covid_behaviours, package = \"epidatasets\")\npop_dat <- state_census %>% select(abbr, pop)\n```\n:::\n\n\nState-wise population data from the 2019 U.S. Census is\navailable from `{epipredict}` and will be used in `layer_population_scaling()`.\n\n\n\nRather than using raw mask-wearing / social-distancing metrics, for the sake\nof illustration, we'll convert both into categorical predictors.\n\n\n::: {.cell layout-align=\"center\" hash='preprocessing-and-models_cache/html/unnamed-chunk-9_fc946e21bc9fa1be4fd6bab0666dd515'}\n::: {.cell-output-display}\n![](preprocessing-and-models_files/figure-html/unnamed-chunk-9-1.svg){fig-align='center' width=90%}\n:::\n:::\n\n\nWe will take a subset of death rate and case rate data from the built-in dataset \n`case_death_rate_subset`.\n\n\n::: {.cell layout-align=\"center\" hash='preprocessing-and-models_cache/html/unnamed-chunk-10_80a089a8a6d7a1e74830826cacc5871c'}\n\n```{.r .cell-code}\njhu <- filter(\n  case_death_rate_subset,\n  time_value >= \"2021-06-04\",\n  time_value <= \"2021-12-31\",\n  geo_value %in% c(\"ca\", \"fl\", \"tx\", \"ny\", \"nj\")\n)\n```\n:::\n\n\nPreprocessing steps will again rely on functions from the `epipredict` package \nas well as the `recipes` package.\nThere are also many functions in the `recipes` package that allow for \n[scalar transformations](https://recipes.tidymodels.org/reference/#step-functions-individual-transformations),\nsuch as log transformations and data centering. In our case, we will \ncenter the numerical predictors to allow for a more meaningful interpretation of\nthe intercept. \n\n\n::: {.cell layout-align=\"center\" hash='preprocessing-and-models_cache/html/unnamed-chunk-11_2fb56af2f7c6d9d8b32c7c071d1446c6'}\n\n```{.r .cell-code}\njhu <- jhu %>%\n  mutate(geo_value_factor = as.factor(geo_value)) %>%\n  left_join(ctis_covid_behaviours, by = c(\"geo_value\", \"time_value\")) %>%\n  as_epi_df()\n\nr <- epi_recipe(jhu) %>%\n  add_role(geo_value_factor, new_role = \"predictor\") %>%\n  step_dummy(geo_value_factor) %>%\n  step_epi_lag(case_rate, death_rate, lag = c(0, 7, 14)) %>%\n  step_mutate(\n    masking = cut_number(masking, 5),\n    distancing = cut_number(distancing, 5)\n  ) %>%\n  step_epi_ahead(death_rate, ahead = 7, role = \"outcome\") %>%\n  step_center(contains(\"lag\"), role = \"predictor\") %>%\n  step_epi_naomit()\n```\n:::\n\n\nAs a sanity check we can examine the structure of the training data:\n\n::: {.cell layout-align=\"center\" hash='preprocessing-and-models_cache/html/unnamed-chunk-12_fcfc398d986b21bb83903a1497923da1'}\n\n```{.r .cell-code}\nglimpse(bake(prep(r, jhu), jhu))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> Rows: 985\n#> Columns: 17\n#> $ time_value          <date> 2021-06-18, 2021-06-18, 2021-06-18, 2021-06-18…\n#> $ geo_value           <chr> \"ca\", \"fl\", \"nj\", \"ny\", \"tx\", \"ca\", \"fl\", \"nj\",…\n#> $ case_rate           <dbl> 2.382641, 6.635633, 2.771139, 1.959257, 3.50565…\n#> $ death_rate          <dbl> 0.0373762, 0.1906224, 0.0707662, 0.0554089, 0.0…\n#> $ masking             <fct> \"(69.7,85]\", \"(52.8,60.2]\", \"(60.2,63.9]\", \"(60…\n#> $ distancing          <fct> \"(27,43]\", \"(21.1,27]\", \"(27,43]\", \"(27,43]\", \"…\n#> $ geo_value_factor_fl <dbl> 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,…\n#> $ geo_value_factor_nj <dbl> 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,…\n#> $ geo_value_factor_ny <dbl> 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,…\n#> $ geo_value_factor_tx <dbl> 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,…\n#> $ lag_0_case_rate     <dbl> -24.55902, -20.30603, -24.17052, -24.98241, -23…\n#> $ lag_7_case_rate     <dbl> -24.28505, -17.44078, -23.74271, -24.00795, -19…\n#> $ lag_14_case_rate    <dbl> -24.61817, -20.99358, -24.55491, -23.72352, -22…\n#> $ lag_0_death_rate    <dbl> -0.2444974, -0.0912512, -0.2111074, -0.2264647,…\n#> $ lag_7_death_rate    <dbl> -0.1875259, -0.0978243, -0.1869826, -0.2035624,…\n#> $ lag_14_death_rate   <dbl> -0.1980493, -0.1431793, -0.1532078, -0.1651456,…\n#> $ ahead_7_death_rate  <dbl> 0.1037824, 0.1426382, 0.0964993, 0.0347229, 0.0…\n```\n:::\n:::\n\n\nBefore directly predicting the results, we need to add postprocessing layers to\nobtain the death counts instead of death rates. Note that the rates used so\nfar are \"per 100K people\" rather than \"per person\". We'll also use quantile\nregression with the `quantile_reg` engine rather than ordinary least squares\nto create median predictions and a 90% prediction interval.\n\n\n::: {.cell layout-align=\"center\" hash='preprocessing-and-models_cache/html/unnamed-chunk-13_ddf56bb37ad1c3b42127e4577dcf6985'}\n\n```{.r .cell-code}\nf <- frosting() %>%\n  layer_predict() %>%\n  layer_add_target_date(\"2022-01-07\") %>%\n  layer_add_forecast_date() %>%\n  layer_threshold(.pred, lower = 0) %>%\n  layer_quantile_distn() %>%\n  layer_point_from_distn() %>%\n  layer_naomit(.pred) %>%\n  layer_population_scaling(\n    contains(\".pred\"),\n    df = pop_dat,\n    rate_rescaling = 1e5,\n    by = c(\"geo_value\" = \"abbr\"),\n    df_pop_col = \"pop\"\n  )\n\nwf <- epi_workflow(r, quantile_reg(quantile_levels = c(.05, .5, .95))) %>%\n  fit(jhu) %>%\n  add_frosting(f)\n\nlatest <- get_test_data(recipe = r, x = jhu)\np <- predict(wf, latest) %>%\n  select(-time_value) %>%\n  as_tibble()\np\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> # A tibble: 5 × 7\n#>   geo_value .pred target_date forecast_date        .pred_distn .pred_scaled\n#>   <chr>     <dbl> <date>      <date>                    <dist>        <dbl>\n#> 1 ca        0.181 2022-01-07  2021-12-31    quantiles(0.18)[2]         71.6\n#> 2 fl        0.348 2022-01-07  2021-12-31    quantiles(0.36)[2]         74.7\n#> 3 nj        0.646 2022-01-07  2021-12-31    quantiles(0.64)[2]         57.4\n#> 4 ny        0.698 2022-01-07  2021-12-31    quantiles(0.69)[2]        136. \n#> 5 tx        0.299 2022-01-07  2021-12-31     quantiles(0.3)[2]         86.8\n#> # ℹ 1 more variable: .pred_distn_scaled <dist>\n```\n:::\n:::\n\n\nThe columns marked `*_scaled` (unfortunately, some of these\nare hidden above) \nhave been rescaled to the correct units, in this\ncase `deaths` rather than deaths per 100K people (these remain in `.pred`).\n\nTo look at the prediction intervals:\n\n::: {.cell layout-align=\"center\" hash='preprocessing-and-models_cache/html/unnamed-chunk-14_ff67c86ce4610a15216ab8282b701524'}\n\n```{.r .cell-code}\np %>%\n  select(geo_value, target_date, .pred_scaled, .pred_distn_scaled) %>%\n  pivot_quantiles_wider(.pred_distn_scaled)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> # A tibble: 5 × 5\n#>   geo_value target_date .pred_scaled `0.25` `0.75`\n#>   <chr>     <date>             <dbl>  <dbl>  <dbl>\n#> 1 ca        2022-01-07          71.6   48.8   94.0\n#> 2 fl        2022-01-07          74.7   48.4  104. \n#> 3 nj        2022-01-07          57.4   45.5   68.7\n#> 4 ny        2022-01-07         136.   108.   163. \n#> 5 tx        2022-01-07          86.8   68.6  107.\n```\n:::\n:::\n\n\n\nLast but not least, let's take a look at the regression fit and check the \ncoefficients:\n\n::: {.cell layout-align=\"center\" hash='preprocessing-and-models_cache/html/unnamed-chunk-15_ba04dff1d70f15ab185e944bdd928a86'}\n::: {.cell-output .cell-output-stdout}\n```\n#> Call:\n#> quantreg::rq(formula = ..y ~ ., tau = ~c(0.05, 0.5, 0.95), data = data, \n#>     na.action = stats::na.omit, method = \"br\", model = FALSE)\n#> \n#> Coefficients:\n#>                        tau= 0.05     tau= 0.50    tau= 0.95\n#> (Intercept)          0.210811625  0.2962574475  0.417583265\n#> geo_value_factor_fl  0.032085820  0.0482361119  0.171126713\n#> geo_value_factor_nj  0.007313762 -0.0033797953 -0.025251865\n#> geo_value_factor_ny -0.001489163 -0.0199485947 -0.032635584\n#> geo_value_factor_tx  0.029077485  0.0391980273  0.071961515\n#> lag_0_case_rate     -0.001636588 -0.0011625693 -0.001430622\n#> lag_7_case_rate      0.004700752  0.0057822095  0.006912655\n#> lag_14_case_rate     0.001715816  0.0004224753  0.003448733\n#> lag_0_death_rate     0.462341754  0.5274192012  0.164856372\n#> lag_7_death_rate    -0.007368501  0.1132903956  0.172687438\n#> lag_14_death_rate   -0.072500707 -0.0270474349  0.181279299\n#> \n#> Degrees of freedom: 950 total; 939 residual\n```\n:::\n:::\n\n\n## Classification\n\nSometimes it is preferable to create a predictive model for surges or upswings\nrather than for raw values. In this case,\nthe target is to predict if the future will have increased case rates (denoted `up`),\ndecreased case rates (`down`), or flat case rates (`flat`) relative to the current\nlevel. Such models may be \nreferred to as \"hotspot prediction models\". We will follow the analysis \nin [McDonald, Bien, Green, Hu, et al.](#references) but extend the application\nto predict three categories instead of two. \n\nHotspot prediction uses a categorical outcome variable defined in terms of the \nrelative change of $Y_{\\ell, t+a}$ compared to $Y_{\\ell, t}$. \nWhere $Y_{\\ell, t}$ denotes the case rates in location $\\ell$ at time $t$. \nWe define the response variables as follows:\n\n$$\n Z_{\\ell, t}=\n    \\begin{cases}\n      \\text{up}, & \\text{if}\\ Y^{\\Delta}_{\\ell, t} > 0.25 \\\\ \n      \\text{down}, & \\text{if}\\  Y^{\\Delta}_{\\ell, t} < -0.20\\\\\n      \\text{flat}, & \\text{otherwise}\n    \\end{cases}\n$$\n\nwhere $Y^{\\Delta}_{\\ell, t} = (Y_{\\ell, t}- Y_{\\ell, t-7})\\ /\\ (Y_{\\ell, t-7})$. \nWe say location $\\ell$ is a hotspot at time $t$ when $Z_{\\ell,t}$ is \n`up`, meaning the number of newly reported cases over the past 7 days has \nincreased by at least 25% compared to the preceding week. When $Z_{\\ell,t}$ \nis categorized as `down`, it suggests that there has been at least a 20% \ndecrease in newly reported cases over the past 7 days (a 20% decrease is the inverse of a 25% increase). Otherwise, we will \nconsider the trend to be `flat`. \n\nThe expression of the multinomial regression we will use is as follows:\n$$\n\\pi_{j}(x) = \\text{Pr}(Z_{\\ell,t} = j|x) = \\frac{e^{g_j(x)}}{1 + \\sum_{k=0}^2 g_j(x) }\n$$\nwhere $j$ is either down, flat, or up\n\n$$\n\\begin{aligned}\ng_{\\text{down}}(x) &= 0,\\\\\ng_{\\text{flat}}(x) &= \n\\log\\left(\\frac{Pr(Z_{\\ell,t}=\\text{flat}|x)}{Pr(Z_{\\ell,t}=\\text{down}|x)}\\right) = \n\\beta_{10} + \\beta_{11}t + \\delta_{10} s_{\\text{state}_1} +\n\\delta_{11} s_{\\text{state}_2} + \\cdots \\nonumber \\\\\n&\\quad +\\ \\beta_{12} Y^{\\Delta}_{\\ell, t} +\n\\beta_{13} Y^{\\Delta}_{\\ell, t-7}, \\\\\ng_{\\text{flat}}(x) &= \\log\\left(\\frac{Pr(Z_{\\ell,t}=\\text{up}|x)}{Pr(Z_{\\ell,t}=\\text{down}|x)}\\right) = \n\\beta_{20} + \\beta_{21}t + \\delta_{20} s_{\\text{state}_1} +\n\\delta_{21} s_{\\text{state}_2} + \\cdots \\nonumber \\\\\n&\\quad +\\ \\beta_{22} Y^{\\Delta}_{\\ell, t} +\n\\beta_{23} Y^{\\Delta}_{\\ell, t-7}.\n\\end{aligned}\n$$\n\n\nPreprocessing steps are similar to the previous models with an additional step \nof categorizing the response variables. Again, we will use a subset of death rate and case rate data from our built-in dataset \n`case_death_rate_subset`.\n\n::: {.cell layout-align=\"center\" hash='preprocessing-and-models_cache/html/unnamed-chunk-16_6c59ca34a0fd30f1f204b03181f28c88'}\n\n```{.r .cell-code}\njhu_rates <- case_death_rate_subset %>%\n  dplyr::filter(\n    time_value >= \"2021-06-04\",\n    time_value <= \"2021-12-31\",\n    geo_value %in% c(\"ca\", \"fl\", \"tx\", \"ny\", \"nj\")\n  ) %>%\n  mutate(geo_value_factor = as.factor(geo_value))\n\nr <- epi_recipe(jhu_rates) %>%\n  add_role(time_value, new_role = \"predictor\") %>%\n  step_dummy(geo_value_factor) %>%\n  step_growth_rate(case_rate, role = \"none\", prefix = \"gr_\") %>%\n  step_epi_lag(starts_with(\"gr_\"), lag = c(0, 7, 14)) %>%\n  step_epi_ahead(starts_with(\"gr_\"), ahead = 7, role = \"none\") %>%\n  # note recipes::step_cut() has a bug in it, or we could use that here\n  step_mutate(\n    response = cut(\n      ahead_7_gr_7_rel_change_case_rate,\n      breaks = c(-Inf, -0.2, 0.25, Inf) / 7, # division gives weekly not daily\n      labels = c(\"down\", \"flat\", \"up\")\n    ),\n    role = \"outcome\"\n  ) %>%\n  step_rm(has_role(\"none\"), has_role(\"raw\")) %>%\n  step_epi_naomit()\n```\n:::\n\n\nWe will fit the multinomial regression and examine the predictions:\n\n\n::: {.cell layout-align=\"center\" hash='preprocessing-and-models_cache/html/unnamed-chunk-17_f55e79fcffe78515bd0042409ccfa0bc'}\n\n```{.r .cell-code}\nwf <- epi_workflow(r, parsnip::multinom_reg()) %>%\n  fit(jhu_rates)\n\nlatest <- get_test_data(recipe = r, x = jhu_rates)\npredict(wf, latest) %>% filter(!is.na(.pred_class))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> An `epi_df` object, 5 x 3 with metadata:\n#> * geo_type  = state\n#> * time_type = day\n#> * as_of     = 2022-05-31 12:08:25\n#> \n#> # A tibble: 5 × 3\n#>   geo_value time_value .pred_class\n#> * <chr>     <date>     <fct>      \n#> 1 ca        2021-12-31 up         \n#> 2 fl        2021-12-31 up         \n#> 3 nj        2021-12-31 up         \n#> 4 ny        2021-12-31 up         \n#> 5 tx        2021-12-31 up\n```\n:::\n:::\n\n\nWe can also look at the estimated coefficients and model summary information:\n\n::: {.cell layout-align=\"center\" hash='preprocessing-and-models_cache/html/unnamed-chunk-18_118e02a282350ab72791be1f72b553d2'}\n\n```{.r .cell-code}\nextract_fit_engine(wf)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> Call:\n#> nnet::multinom(formula = ..y ~ ., data = data, trace = FALSE)\n#> \n#> Coefficients:\n#>      (Intercept)  time_value geo_value_factor_fl geo_value_factor_nj\n#> flat   -144.2225 0.007754541          -1.3251323            1.137559\n#> up     -133.1994 0.007082196          -0.5081303            1.562700\n#>      geo_value_factor_ny geo_value_factor_tx lag_0_gr_7_rel_change_case_rate\n#> flat            24.74419          -0.3345776                        18.96354\n#> up              24.84975          -0.3176996                        33.79518\n#>      lag_7_gr_7_rel_change_case_rate lag_14_gr_7_rel_change_case_rate\n#> flat                        33.19049                         7.157042\n#> up                          56.52374                         4.684437\n#> \n#> Residual Deviance: 1157.928 \n#> AIC: 1193.928\n```\n:::\n:::\n\n\nOne could also use a formula in `epi_recipe()` to achieve the same results as \nabove. However, only one of `add_formula()`, `add_recipe()`, or \n`workflow_variables()` can be specified. For the purpose of demonstrating \n`add_formula` rather than `add_recipe`, we will `prep` and `bake` our recipe to\nreturn a `data.frame` that could be used for model fitting.\n\n::: {.cell layout-align=\"center\" hash='preprocessing-and-models_cache/html/unnamed-chunk-19_95018fa1894b856edd76e784a2756aa6'}\n\n```{.r .cell-code}\nb <- bake(prep(r, jhu_rates), jhu_rates)\n\nepi_workflow() %>%\n  add_formula(\n    response ~ geo_value + time_value + lag_0_gr_7_rel_change_case_rate +\n      lag_7_gr_7_rel_change_case_rate + lag_14_gr_7_rel_change_case_rate\n  ) %>%\n  add_model(parsnip::multinom_reg()) %>%\n  fit(data = b)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> ══ Workflow [trained] ═══════════════════════════════════════════════════════\n#> Preprocessor: Formula\n#> Model: multinom_reg()\n#> \n#> ── Preprocessor ─────────────────────────────────────────────────────────────\n#> response ~ geo_value + time_value + lag_0_gr_7_rel_change_case_rate + \n#>     lag_7_gr_7_rel_change_case_rate + lag_14_gr_7_rel_change_case_rate\n#> \n#> ── Model ────────────────────────────────────────────────────────────────────\n#> Call:\n#> nnet::multinom(formula = ..y ~ ., data = data, trace = FALSE)\n#> \n#> Coefficients:\n#>      (Intercept) geo_valuefl geo_valuenj geo_valueny geo_valuetx  time_value\n#> flat   -144.2169  -1.3265549    1.133934    24.75059  -0.3335115 0.007754345\n#> up     -133.3502  -0.5120186    1.559702    24.85665  -0.3158343 0.007090249\n#>      lag_0_gr_7_rel_change_case_rate lag_7_gr_7_rel_change_case_rate\n#> flat                        19.02252                        33.20794\n#> up                          33.84660                        56.57061\n#>      lag_14_gr_7_rel_change_case_rate\n#> flat                         7.140372\n#> up                           4.668915\n#> \n#> Residual Deviance: 1157.919 \n#> AIC: 1193.919\n```\n:::\n:::\n\n\n<!--\n\n## Benefits of Lagging and Leading in `epipredict`\n\nThe `step_epi_ahead` and `step_epi_lag` functions in the `epipredict` package\nis handy for creating correct lags and leads for future predictions. \n\nLet's examine what happens with one month of data for one location:\n\n::: {.cell layout-align=\"center\" hash='preprocessing-and-models_cache/html/unnamed-chunk-20_0a1fe4b7ad64a1a8421a1ba2ed248f5c'}\n\n```{.r .cell-code}\nex <- filter(\n  case_death_rate_subset,\n  time_value >= \"2021-12-01\",\n  time_value <= \"2021-12-31\",\n  geo_value == \"ca\"\n)\nex\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> An `epi_df` object, 31 x 4 with metadata:\n#> * geo_type  = state\n#> * time_type = day\n#> * as_of     = 2022-05-31 12:08:25\n#> \n#> # A tibble: 31 × 4\n#>   geo_value time_value case_rate death_rate\n#> * <chr>     <date>         <dbl>      <dbl>\n#> 1 ca        2021-12-01      12.5      0.173\n#> 2 ca        2021-12-02      15.5      0.207\n#> 3 ca        2021-12-03      16.0      0.235\n#> 4 ca        2021-12-04      16.6      0.233\n#> 5 ca        2021-12-05      16.7      0.232\n#> 6 ca        2021-12-06      17.3      0.194\n#> # ℹ 25 more rows\n```\n:::\n:::\n\n\nWe want to predict death rates on 2022-01-07, which is 7 days \nahead of the latest available date in our dataset. \n\nWe will compare two methods of trying to create lags and leads:\n\n::: {.cell layout-align=\"center\" hash='preprocessing-and-models_cache/html/unnamed-chunk-21_1a56cb48e40fa646e310c62fcd7f7a5f'}\n\n```{.r .cell-code}\nprepped_epi <- epi_recipe(ex) %>%\n  step_epi_lag(case_rate, death_rate, lag = c(0, 7, 14)) %>%\n  step_epi_ahead(death_rate, ahead = 7) %>%\n  step_epi_naomit() %>%\n  prep()\n\nbaked_epi <- bake(prepped_epi, ex)\nbaked_epi\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> # A tibble: 17 × 11\n#>   time_value geo_value case_rate death_rate lag_0_case_rate lag_7_case_rate\n#>   <date>     <chr>         <dbl>      <dbl>           <dbl>           <dbl>\n#> 1 2021-12-15 ca             15.8      0.157            15.8            18.0\n#> 2 2021-12-16 ca             16.3      0.155            16.3            17.4\n#> 3 2021-12-17 ca             16.9      0.158            16.9            17.4\n#> 4 2021-12-18 ca             17.6      0.164            17.6            17.2\n#> 5 2021-12-19 ca             19.1      0.165            19.1            16.3\n#> 6 2021-12-20 ca             20.6      0.164            20.6            16.0\n#> # ℹ 11 more rows\n#> # ℹ 5 more variables: lag_14_case_rate <dbl>, lag_0_death_rate <dbl>, …\n```\n:::\n\n```{.r .cell-code}\nprepped_rec <- epi_recipe(ex) %>%\n  step_lag(case_rate, death_rate, lag = c(7, 14)) %>% # lags must be positive\n  step_mutate(lag_0_death_rate = death_rate, lag_0_case_rate = case_rate) %>%\n  step_mutate(ahead_7_death_rate = lead(death_rate, 7), role = \"outcome\") %>%\n  step_naomit(all_predictors(), all_outcomes()) %>%\n  prep()\n\nbaked_rec <- bake(prepped_rec, ex)\nbaked_rec\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> An `epi_df` object, 31 x 11 with metadata:\n#> * geo_type  = state\n#> * time_type = day\n#> * as_of     = 2022-05-31 12:08:25\n#> \n#> # A tibble: 31 × 11\n#>   time_value geo_value case_rate death_rate lag_7_case_rate lag_14_case_rate\n#> * <date>     <chr>         <dbl>      <dbl>           <dbl>            <dbl>\n#> 1 2021-12-01 ca             12.5      0.173              NA               NA\n#> 2 2021-12-02 ca             15.5      0.207              NA               NA\n#> 3 2021-12-03 ca             16.0      0.235              NA               NA\n#> 4 2021-12-04 ca             16.6      0.233              NA               NA\n#> 5 2021-12-05 ca             16.7      0.232              NA               NA\n#> 6 2021-12-06 ca             17.3      0.194              NA               NA\n#> # ℹ 25 more rows\n#> # ℹ 5 more variables: lag_7_death_rate <dbl>, lag_14_death_rate <dbl>, …\n```\n:::\n:::\n\n\nNotice the difference in number of rows `b1` and `b2` returns. This is because \nthe second version, the one that doesn't use `step_epi_ahead` and `step_epi_lag`,\nhas omitted dates compared to the one that used the `epipredict` functions.\n\n::: {.cell layout-align=\"center\" hash='preprocessing-and-models_cache/html/unnamed-chunk-22_25ec487a31807cc4a794a6b43ea37e09'}\n\n```{.r .cell-code}\ndates_used_by_epi <- baked_epi %>%\n  select(-ahead_7_death_rate) %>%\n  na.omit() %>%\n  pull(time_value)\ndates_used_by_epi\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>  [1] \"2021-12-15\" \"2021-12-16\" \"2021-12-17\" \"2021-12-18\" \"2021-12-19\"\n#>  [6] \"2021-12-20\" \"2021-12-21\" \"2021-12-22\" \"2021-12-23\" \"2021-12-24\"\n#> [11] \"2021-12-25\" \"2021-12-26\" \"2021-12-27\" \"2021-12-28\" \"2021-12-29\"\n#> [16] \"2021-12-30\" \"2021-12-31\"\n```\n:::\n\n```{.r .cell-code}\ndates_used_by_rec <- baked_rec %>%\n  select(-ahead_7_death_rate) %>%\n  na.omit() %>%\n  pull(time_value)\ndates_used_by_rec\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>  [1] \"2021-12-15\" \"2021-12-16\" \"2021-12-17\" \"2021-12-18\" \"2021-12-19\"\n#>  [6] \"2021-12-20\" \"2021-12-21\" \"2021-12-22\" \"2021-12-23\" \"2021-12-24\"\n#> [11] \"2021-12-25\" \"2021-12-26\" \"2021-12-27\" \"2021-12-28\" \"2021-12-29\"\n#> [16] \"2021-12-30\" \"2021-12-31\"\n```\n:::\n:::\n\n\nThe model that is trained based on the `{recipes}` functions will predict 7 days \nahead from 2021-12-31\ninstead of 7 days ahead from 2021-12-31.\n\n-->\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}