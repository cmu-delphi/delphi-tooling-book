{
  "hash": "7c66e788ab57bec457342c2096be2e3d",
  "result": {
    "markdown": "# Pseudo-prospective forecast inspection\n\n\n::: {.cell}\n\n:::\n\n\n\nA key function from the epiprocess package is `epi_slide()`, which allows the\nuser to apply a function or formula-based computation over variables in an\n`epi_df` over a running window of `n` time steps (see the following `epiprocess`\nvignette to go over the basics of the function: [\"Slide a computation over\nsignal values\"](https://cmu-delphi.github.io/epiprocess/articles/slide.html)).\nThe equivalent sliding method for an `epi_archive` object can be called by using\nthe wrapper function `epix_slide()` (refer to the following vignette for the\nbasics of the function: [\"Work with archive objects and data\nrevisions\"](https://cmu-delphi.github.io/epiprocess/articles/archive.html)). The\nkey difference from `epi_slide()` is that it performs version-aware\ncomputations. That is, the function only uses data that would have been\navailable as of time t for that reference time.\n\nIn this vignette, we use `epi_slide()` and `epix_slide()` for backtesting our\n`arx_forecaster` on historical COVID-19 case data from the US and from Canada.\nMore precisely, we first demonstrate using `epi_slide()` to slide ARX\nforecasters over an `epi_df` object and compare the results obtained from using\ndifferent forecasting engines. We then compare these simple retrospective\nforecasts to more proper \"pseudoprospective\" forecasts generated using snapshots\nof the data that was available in real time, using `epix_slide()`.\n\n## Comparing different forecasting engines\n\n### Example using CLI and case data from US states \n\nFirst, we download the version history (i.e. archive) of the percentage of\ndoctorâ€™s visits with CLI (COVID-like illness) computed from medical insurance\nclaims and the number of new confirmed COVID-19 cases per 100,000 population\n(daily) for all 50 states from the COVIDcast API. We process as before, with the\nmodification that we use `sync = \"locf\"` in `epix_merge()` so that the last\nversion of each observation can be carried forward to extrapolate unavailable\nversions for the less up-to-date input archive.\n\n\n::: {.cell layout-align=\"center\" hash='sliding-forecasters_cache/html/grab-epi-data_d4d80a61c31b62ea1a5d61f1072177bf'}\n\n```{.r .cell-code}\nus_raw_history_dfs <-\n  readRDS(system.file(\"extdata\", \"all_states_covidcast_signals.rds\",\n    package = \"epipredict\", mustWork = TRUE\n  ))\n\nus_cli_archive <- us_raw_history_dfs[[1]] %>%\n  select(geo_value, time_value, version = issue, percent_cli = value) %>%\n  as_epi_archive(compactify = TRUE)\nus_cases_archive <- us_raw_history_dfs[[2]] %>%\n  select(geo_value, time_value, version = issue, case_rate = value) %>%\n  as_epi_archive(compactify = TRUE)\n\nus_archive <- epix_merge(\n  us_cli_archive, us_cases_archive,\n  sync = \"locf\", compactify = TRUE\n)\n```\n:::\n\n\nAfter obtaining the latest snapshot of the data, we produce forecasts on that\ndata using the default engine of simple linear regression and compare to a\nrandom forest.\n\nNote that all of the warnings about the forecast date being less than the most\nrecent update date of the data have been suppressed to avoid cluttering the\noutput.\n\n\n::: {.cell layout-align=\"center\" hash='sliding-forecasters_cache/html/make-arx-kweek_e94760e6e189c78095774ec6e5d8dd64'}\n\n```{.r .cell-code}\n# Latest snapshot of data, and forecast dates\nus_latest <- epix_as_of(us_archive, max_version = max(us_archive$versions_end))\nfc_time_values <- seq(\n  from = as.Date(\"2020-08-01\"),\n  to = as.Date(\"2021-11-01\"),\n  by = \"1 month\"\n)\naheads <- c(7, 14, 21, 28)\n\nk_week_ahead <- function(epi_df, outcome, predictors, ahead = 7, engine) {\n  epi_slide(epi_df, ~ arx_forecaster(\n    .x, outcome, predictors, engine,\n    args_list = arx_args_list(ahead = ahead)\n  )$predictions %>%\n    select(-geo_value),\n  before = 120L - 1L,\n  ref_time_values = fc_time_values,\n  new_col_name = \"fc\"\n  ) %>%\n    select(geo_value, time_value, starts_with(\"fc\")) %>%\n    mutate(engine_type = engine$engine)\n}\n\n# Generate the forecasts and bind them together\nfc <- bind_rows(\n  map(aheads, ~ k_week_ahead(\n    us_latest, \"case_rate\", c(\"case_rate\", \"percent_cli\"), .x,\n    engine = linear_reg()\n  )) %>%\n    list_rbind(),\n  map(aheads, ~ k_week_ahead(\n    us_latest, \"case_rate\", c(\"case_rate\", \"percent_cli\"), .x,\n    engine = rand_forest(mode = \"regression\")\n  )) %>%\n    list_rbind()\n) %>%\n  pivot_quantiles(contains(\"_distn\"))\n```\n:::\n\n\nHere, `arx_forecaster()` does all the heavy lifting. It creates leads of the\ntarget (respecting time stamps and locations) along with lags of the features\n(here, the response and doctors visits), estimates a forecasting model using the\nspecified engine, creates predictions, and non-parametric confidence bands. \n\nTo see how the predictions compare, we plot them on top of the latest case\nrates. Note that even though we've fitted the model on all states, \nwe'll just display the\nresults for two states, California (CA) and Florida (FL), to get a sense of the\nmodel performance while keeping the graphic simple. \n\n\n::: {.cell layout-align=\"center\" hash='sliding-forecasters_cache/html/plot-arx_cf5ed426dadcf87aa72c873f89ba401b'}\n\n```{.r .cell-code  code-fold=\"true\"}\nfc_cafl <- fc %>% filter(geo_value %in% c(\"ca\", \"fl\"))\nlatest_cafl <- us_latest %>% filter(geo_value %in% c(\"ca\", \"fl\"))\n\nggplot(fc_cafl, aes(fc_target_date, group = time_value, fill = engine_type)) +\n  geom_line(\n    data = latest_cafl, aes(x = time_value, y = case_rate),\n    inherit.aes = FALSE, color = \"gray50\"\n  ) +\n  geom_ribbon(aes(ymin = `0.05`, ymax = `0.95`), alpha = 0.4) +\n  geom_line(aes(y = fc_.pred)) +\n  geom_point(aes(y = fc_.pred), size = 0.5) +\n  geom_vline(aes(xintercept = time_value), linetype = 2, alpha = 0.5) +\n  facet_grid(engine_type ~ geo_value, scales = \"free\") +\n  scale_x_date(minor_breaks = \"month\", date_labels = \"%b %y\") +\n  scale_fill_brewer(palette = \"Set1\") +\n  scale_y_continuous(expand = expansion(c(0, 0.05))) +\n  labs(x = \"Date\", y = \"Reported COVID-19 case rates\") +\n  theme(legend.position = \"none\")\n```\n\n::: {.cell-output-display}\n![](sliding-forecasters_files/figure-html/plot-arx-1.svg){fig-align='center' width=90%}\n:::\n:::\n\n\nFor the two states of interest, simple linear regression clearly performs better\nthan random forest in terms of accuracy of the predictions and does not\nresult in such overconfident predictions (overly narrow confidence bands).\nThough, in general, neither approach produces amazingly accurate forecasts. \nThis could be because\nthe behaviour is rather different across states and the effects of other notable\nfactors such as age and public health measures may be important to account for\nin such forecasting. Including such factors as well as making enhancements such\nas correcting for outliers are some improvements one could make to this simple\nmodel.[^1]\n\n[^1]: Note that, despite the above caveats, simple models like this tend to out-perform many far more complicated models in the online Covid forecasting due to those models' high variance predictions.\n\n### Example using case data from Canada\n\nBy leveraging the flexibility of `epiprocess`, we can apply the same techniques\nto data from other sources. Since some collaborators are in British Columbia,\nCanada, we'll do essentially the same thing for Canada as we did above.\n\nThe [COVID-19 Canada Open Data Working Group](https://opencovid.ca/) collects\ndaily time series data on COVID-19 cases, deaths, recoveries, testing and\nvaccinations at the health region and province levels. Data are collected from\npublicly available sources such as government datasets and news releases.\nUnfortunately, there is no simple versioned source, so we have created our own\nfrom the Github commit history.\n\nFirst, we load versioned case rates at the provincial level. After converting\nthese to 7-day averages (due to highly variable provincial reporting\nmismatches), we then convert the data to an `epi_archive` object, and extract\nthe latest version from it. Finally, we run the same forcasting exercise as for\nthe American data, but here we compare the forecasts produced from using simple\nlinear regression with those from using boosted regression trees.\n\n\n::: {.cell layout-align=\"center\" hash='sliding-forecasters_cache/html/get-can-fc_e71fa828c8e3e33e0763c1dbbe5bc5ce'}\n\n```{.r .cell-code}\n# source(\"drafts/canada-case-rates.R)\ncan <- readRDS(system.file(\n  \"extdata\", \"can_prov_cases.rds\",\n  package = \"epipredict\", mustWork = TRUE\n))\ncan <- can %>%\n  group_by(version, geo_value) %>%\n  arrange(time_value) %>%\n  mutate(cr_7dav = RcppRoll::roll_meanr(case_rate, n = 7L)) %>%\n  as_epi_archive(compactify = TRUE)\n\ncan_latest <- epix_as_of(can, max_version = max(can$DT$version))\n\n# Generate the forecasts, and bind them together\ncan_fc <- bind_rows(\n  map(aheads, ~ k_week_ahead(\n    can_latest, \"cr_7dav\", \"cr_7dav\", .x, linear_reg()\n  )) %>%\n    list_rbind(),\n  map(aheads, ~ k_week_ahead(\n    can_latest, \"cr_7dav\", \"cr_7dav\", .x,\n    boost_tree(mode = \"regression\", trees = 20)\n  )) %>%\n    list_rbind()\n) %>%\n  pivot_quantiles(contains(\"_distn\"))\n```\n:::\n\n\nThe first figure shows the results for all of the provinces using linear regression. \n\n\n::: {.cell layout-align=\"center\" hash='sliding-forecasters_cache/html/plot-can-fc-lr_749e70213871f43929436d4a578868fa'}\n\n```{.r .cell-code  code-fold=\"true\"}\nggplot(\n  can_fc %>% filter(engine_type == \"lm\"),\n  aes(x = fc_target_date, group = time_value)\n) +\n  coord_cartesian(xlim = lubridate::ymd(c(\"2020-12-01\", NA))) +\n  geom_line(\n    data = can_latest, aes(x = time_value, y = cr_7dav),\n    inherit.aes = FALSE, color = \"gray50\"\n  ) +\n  geom_ribbon(aes(ymin = `0.05`, ymax = `0.95`, fill = geo_value),\n    alpha = 0.4\n  ) +\n  geom_line(aes(y = fc_.pred)) +\n  geom_point(aes(y = fc_.pred), size = 0.5) +\n  geom_vline(aes(xintercept = time_value), linetype = 2, alpha = 0.5) +\n  facet_wrap(~geo_value, scales = \"free_y\", ncol = 3) +\n  scale_x_date(minor_breaks = \"month\", date_labels = \"%b %y\") +\n  scale_y_continuous(expand = expansion(c(0, 0.05))) +\n  labs(\n    title = \"Using simple linear regression\", x = \"Date\",\n    y = \"Reported COVID-19 case rates\"\n  ) +\n  theme(legend.position = \"none\")\n```\n\n::: {.cell-output-display}\n![](sliding-forecasters_files/figure-html/plot-can-fc-lr-1.svg){fig-align='center' width=90%}\n:::\n:::\n\n\nCompare those forecasts with a related set using Gradient Boosting.\n\n\n::: {.cell layout-align=\"center\" hash='sliding-forecasters_cache/html/plot-can-fc-boost_145622420fe9517007923111890c3146'}\n\n```{.r .cell-code  code-fold=\"true\"}\nggplot(\n  can_fc %>% filter(engine_type == \"xgboost\"),\n  aes(x = fc_target_date, group = time_value)\n) +\n  coord_cartesian(xlim = lubridate::ymd(c(\"2020-12-01\", NA))) +\n  geom_line(\n    data = can_latest, aes(x = time_value, y = cr_7dav),\n    inherit.aes = FALSE, color = \"gray50\"\n  ) +\n  geom_ribbon(aes(ymin = `0.05`, ymax = `0.95`, fill = geo_value),\n    alpha = 0.4\n  ) +\n  geom_line(aes(y = fc_.pred)) +\n  geom_point(aes(y = fc_.pred), size = 0.5) +\n  geom_vline(aes(xintercept = time_value), linetype = 2, alpha = 0.5) +\n  facet_wrap(~geo_value, scales = \"free_y\", ncol = 3) +\n  scale_x_date(minor_breaks = \"month\", date_labels = \"%b %y\") +\n  scale_y_continuous(expand = expansion(c(0, 0.05))) +\n  labs(\n    title = \"Using boosted regression trees\", x = \"Date\",\n    y = \"Reported COVID-19 case rates\"\n  ) +\n  theme(legend.position = \"none\")\n```\n\n::: {.cell-output-display}\n![](sliding-forecasters_files/figure-html/plot-can-fc-boost-1.svg){fig-align='center' width=90%}\n:::\n:::\n\n\nBoth approaches tend to produce quite volatile forecasts (point predictions)\nand/or are overly confident (very narrow bands), particularly when boosted\nregression trees are used. But as this is meant to be a simple demonstration of\nsliding with different engines in `arx_forecaster`, we may devote another\nvignette to work on improving the predictive modelling using the suite of tools\navailable in epipredict.\n\n## Pseudoprospective vs. unfaithful retrospective forecasting\n\n### Example using case data from US states \n\nWe will now run pseudoprospective forecasts based on properly-versioned data\n(that would have been available in real-time) to forecast future COVID-19 case\nrates from current and past COVID-19 case rates for all states. That is, we can\nmake forecasts on the archive, `us_archive`, and compare those to forecasts on\n(time windows of) the latest data, `us_latest`, using the same general set-up as\nabove. For pseudoprospective forecasting, note that `us_archive` is fed into\n`epix_slide()`, while for simpler (unfaithful) retrospective forecasting,\n`us_latest` is fed into `epi_slide()`. #%% update to include percent_cli after\nthat issue is fixed?\n\n\n::: {.cell layout-align=\"center\" hash='sliding-forecasters_cache/html/make-ar-kweek-asof_21e1c68d47e5580356a43fdfb3832164'}\n\n```{.r .cell-code}\nk_week_versioning <- function(ahead, version = c(\"faithful\", \"unfaithful\")) {\n  version <- match.arg(version)\n  if (version == \"faithful\") {\n    epix_slide(\n      us_archive,\n      ~ arx_forecaster(\n        .x, \"case_rate\", c(\"case_rate\", \"percent_cli\"),\n        args_list = arx_args_list(ahead = ahead)\n      )$predictions,\n      before = 120 - 1,\n      ref_time_values = fc_time_values,\n      new_col_name = \"fc\"\n    ) %>%\n      mutate(version = \"version faithful\") %>%\n      rename(geo_value = \"fc_geo_value\")\n  } else {\n    k_week_ahead(\n      us_latest, \"case_rate\", c(\"case_rate\", \"percent_cli\"),\n      ahead, linear_reg()\n    ) %>% mutate(version = \"not version faithful\")\n  }\n}\n\n# Generate the forecasts, and bind them together\nfc <- bind_rows(\n  map(aheads, ~ k_week_versioning(.x, \"faithful\")) %>% list_rbind(),\n  map(aheads, ~ k_week_versioning(.x, \"unfaithful\")) %>% list_rbind()\n) %>% pivot_quantiles(fc_.pred_distn)\n```\n:::\n\n\nNow we can plot the results on top of the latest case rates. As before, we will only display and focus on the results for FL and CA for simplicity.\n\n\n::: {.cell layout-align=\"center\" hash='sliding-forecasters_cache/html/plot-ar-asof_c6417eaf4d97855d750b9f8aeb315d67'}\n\n```{.r .cell-code  code-fold=\"true\"}\nfc_cafl <- fc %>% filter(geo_value %in% c(\"ca\", \"fl\"))\nlatest_cafl <- us_latest %>% filter(geo_value %in% c(\"ca\", \"fl\"))\n\nggplot(fc_cafl, aes(x = fc_target_date, group = time_value)) +\n  geom_line(\n    data = latest_cafl, aes(x = time_value, y = case_rate),\n    inherit.aes = FALSE, color = \"gray50\"\n  ) +\n  geom_ribbon(aes(ymin = `0.05`, ymax = `0.95`, fill = version), alpha = 0.4) +\n  geom_line(aes(y = fc_.pred)) +\n  geom_point(aes(y = fc_.pred), size = 0.5) +\n  geom_vline(aes(xintercept = time_value), linetype = 2, alpha = 0.5) +\n  facet_grid(version ~ geo_value, scales = \"free\") +\n  scale_x_date(minor_breaks = \"month\", date_labels = \"%b %y\") +\n  scale_y_continuous(expand = expansion(c(0, 0.05))) +\n  labs(x = \"Date\", y = \"Reported COVID-19 case rates\") +\n  scale_fill_brewer(palette = \"Set1\") +\n  theme(legend.position = \"none\")\n```\n\n::: {.cell-output-display}\n![](sliding-forecasters_files/figure-html/plot-ar-asof-1.svg){fig-align='center' width=90%}\n:::\n:::\n\n\nAgain, we observe that the results are not great for these two states, but\nthat's likely due to the simplicity of the model (ex. the omission of key\nfactors such as age and public health measures) and the quality of the data (ex.\nwe have not personally corrected for anomalies in the data).\n\nWe shall leave it to the reader to try the above version aware and unaware\nforecasting exercise on the Canadian case rate data. The above code for the\nAmerican state data should be readily adaptable for this purpose.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}