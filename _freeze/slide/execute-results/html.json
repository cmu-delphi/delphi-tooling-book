{
  "hash": "74d3db577831e2a6d86c6a6c2939a7d3",
  "result": {
    "markdown": "# Sliding computations {#sec-sliding}\n\nA central tool in the `{epiprocess}` package is `epi_slide()`, which is based\non the powerful functionality provided in the \n[`slider`](https://cran.r-project.org/web/packages/slider) package. In\n`{epiprocess}`, to \"slide\" means to apply a computation---represented as a\nfunction or formula---over a sliding/rolling data window. Suitable\ngroupings can always be achieved by a preliminary call to `group_by()`.\n\nBy default, the meaning of one time step is inferred from the `time_value`\ncolumn of the `epi_df` object under consideration, based on the way this column\nunderstands addition and subtraction. For example, if the time values are coded\nas `Date` objects, then one time step is one day, since \n`as.Date(\"2022-01-01\") + 1` equals `as.Date(\"2022-01-02\")`. Alternatively, the time step can be specified\nmanually in the call to `epi_slide()`; you can read the documentation for more\ndetails. Furthermore, the alignment of the running window used in `epi_slide()`\ncan be \"right\", \"center\", or \"left\"; the default is \"right\", and is what we use\nin this vignette.\n\nAs in getting started guide, we'll fetch daily reported COVID-19 cases from CA,\nFL, NY, and TX (note: here we're using new, not cumulative cases) using the\n[`epidatr`](https://github.com/cmu-delphi/epidatr) package,\nand then convert this to `epi_df` format.\n\n\n\n\n::: {.cell layout-align=\"center\" hash='slide_cache/html/unnamed-chunk-2_feb3ab09af2a656b7552aabd4fb92768'}\n\n```{.r .cell-code}\nlibrary(epidatr)\nlibrary(epiprocess)\nlibrary(epipredict)\n```\n:::\n\n\nThe example data we'll use is part of the package and has 2,684 rows and 3 columns.\n\n\n::: {.cell layout-align=\"center\" hash='slide_cache/html/unnamed-chunk-3_de5ebab547ecc5d1e32e4f6b65aac60b'}\n\n```{.r .cell-code}\ndata(jhu_csse_daily_subset)\nx <- jhu_csse_daily_subset %>%\n  select(geo_value, time_value, cases) %>%\n  arrange(geo_value, time_value) %>%\n  as_epi_df()\n```\n:::\n\n\n\n## Slide with a formula\n\nWe first demonstrate how to apply a 7-day trailing average to the daily cases in\norder to smooth the signal, by passing in a formula for the first argument of\n`epi_slide()`. To do this computation per state, we first call `group_by()`.\n\n\n::: {.cell layout-align=\"center\" hash='slide_cache/html/unnamed-chunk-4_13b28969f566d77bd0c5e1e88a551491'}\n\n```{.r .cell-code}\nx %>%\n  group_by(geo_value) %>%\n  epi_slide(~ mean(.x$cases), before = 6) %>%\n  ungroup()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> An `epi_df` object, 4,026 x 4 with metadata:\n#> * geo_type  = state\n#> * time_type = day\n#> * as_of     = 2022-05-23 13:17:07\n#> \n#> # A tibble: 4,026 × 4\n#>   geo_value time_value cases slide_value\n#> * <chr>     <date>     <dbl>       <dbl>\n#> 1 ca        2020-03-01     6        6   \n#> 2 ca        2020-03-02     4        5   \n#> 3 ca        2020-03-03     6        5.33\n#> 4 ca        2020-03-04    11        6.75\n#> 5 ca        2020-03-05    10        7.4 \n#> 6 ca        2020-03-06    18        9.17\n#> # ℹ 4,020 more rows\n```\n:::\n:::\n\n\nThe formula specified has access to all non-grouping columns present in the\noriginal `epi_df` object (and must refer to them with the prefix `.x$`). As we\ncan see, the function `epi_slide()` returns an `epi_df` object with a new column\nappended that contains the results (from sliding), named `slide_value` as the\ndefault. We can of course change this post hoc, or we can instead specify a new\nname up front using the `new_col_name` argument:\n\n\n::: {.cell layout-align=\"center\" hash='slide_cache/html/unnamed-chunk-5_cf02a2675d6bbdf3eb316e16406a82e5'}\n\n```{.r .cell-code}\nx %>%\n  group_by(geo_value) %>%\n  epi_slide(~ mean(.x$cases), before = 6, new_col_name = \"cases_7dav\") %>%\n  ungroup()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> An `epi_df` object, 4,026 x 4 with metadata:\n#> * geo_type  = state\n#> * time_type = day\n#> * as_of     = 2022-05-23 13:17:07\n#> \n#> # A tibble: 4,026 × 4\n#>   geo_value time_value cases cases_7dav\n#> * <chr>     <date>     <dbl>      <dbl>\n#> 1 ca        2020-03-01     6       6   \n#> 2 ca        2020-03-02     4       5   \n#> 3 ca        2020-03-03     6       5.33\n#> 4 ca        2020-03-04    11       6.75\n#> 5 ca        2020-03-05    10       7.4 \n#> 6 ca        2020-03-06    18       9.17\n#> # ℹ 4,020 more rows\n```\n:::\n:::\n\n\nSome other information is available in additional variables:\n\n* `.group_key` is a one-row tibble containing the values of the grouping\n  variables for the associated group\n* `.ref_time_value` is the reference time value the time window was based on\n\nLike in `group_modify()`, there are alternative names for these variables as\nwell: `.` can be used instead of `.x`, `.y` instead of `.group_key`, and `.z`\ninstead of `.ref_time_value`.\n\n## Slide with a function \n\nWe can also pass a function for the first argument in `epi_slide()`. In this\ncase, the passed function must accept the following arguments:\n\nIn this case, the passed function `f` must accept the following arguments: a\ndata frame with the same column names as the original object, minus any grouping\nvariables, containing the time window data for one group-`ref_time_value`\ncombination; followed by a one-row tibble containing the values of the grouping\nvariables for the associated group; followed by the associated `ref_time_value`.\nIt can accept additional arguments; `epi_slide()` will forward any `...` args it\nreceives to `f`.\n\nRecreating the last example of a 7-day trailing average:\n\n\n::: {.cell layout-align=\"center\" hash='slide_cache/html/unnamed-chunk-6_63c4174606b3c7249ee9ddd5f3171d78'}\n\n```{.r .cell-code}\nx %>%\n  group_by(geo_value) %>%\n  epi_slide(function(x, gk, rtv) mean(x$cases),\n    before = 6, new_col_name = \"cases_7dav\"\n  ) %>%\n  ungroup()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> An `epi_df` object, 4,026 x 4 with metadata:\n#> * geo_type  = state\n#> * time_type = day\n#> * as_of     = 2022-05-23 13:17:07\n#> \n#> # A tibble: 4,026 × 4\n#>   geo_value time_value cases cases_7dav\n#> * <chr>     <date>     <dbl>      <dbl>\n#> 1 ca        2020-03-01     6       6   \n#> 2 ca        2020-03-02     4       5   \n#> 3 ca        2020-03-03     6       5.33\n#> 4 ca        2020-03-04    11       6.75\n#> 5 ca        2020-03-05    10       7.4 \n#> 6 ca        2020-03-06    18       9.17\n#> # ℹ 4,020 more rows\n```\n:::\n:::\n\n\n## Slide the tidy way\n\nPerhaps the most convenient way to setup a computation in `epi_slide()` is to\npass in an expression for tidy evaluation. In this case, we can simply define\nthe name of the new column directly as part of the expression, setting it equal\nto a computation in which we can access any columns of `x` by name, just as we\nwould in a call to `dplyr::mutate()`, or any of the `dplyr` verbs. For example:\n\n\n::: {.cell layout-align=\"center\" hash='slide_cache/html/unnamed-chunk-7_86937bdc4f9b436be5721bf89cb48542'}\n\n```{.r .cell-code}\nx <- x %>%\n  group_by(geo_value) %>%\n  epi_slide(cases_7dav = mean(cases), before = 6) %>%\n  ungroup()\n```\n:::\n\nIn addition to referring to individual columns by name, you can refer to the\ntime window data as an `epi_df` or `tibble` using `.x`.  Similarly, the other arguments of the function format are available through the magic names `.group_key` and `.ref_time_value`, and the tidyverse \"pronouns\" `.data` and `.env` can also be used.\n\nAs a simple sanity check, we visualize the 7-day trailing averages computed on\ntop of the original counts.\n\n\n::: {.cell layout-align=\"center\" hash='slide_cache/html/unnamed-chunk-8_4be7d7ffd8b84de93dbeff6c68bf1113'}\n\n```{.r .cell-code  code-fold=\"true\"}\ncols <- RColorBrewer::brewer.pal(7, \"Set1\")[-6]\nggplot(x, aes(x = time_value)) +\n  geom_col(aes(y = cases, fill = geo_value),\n    alpha = 0.5,\n    show.legend = FALSE\n  ) +\n  scale_y_continuous(expand = expansion(c(0, 0.05))) +\n  geom_line(aes(y = cases_7dav, col = geo_value), show.legend = FALSE) +\n  scale_fill_manual(values = cols) +\n  scale_color_manual(values = cols) +\n  facet_wrap(~geo_value, scales = \"free_y\") +\n  scale_x_date(minor_breaks = \"month\", date_labels = \"%b %Y\") +\n  labs(x = \"Date\", y = \"Reported COVID-19 cases\")\n```\n\n::: {.cell-output-display}\n![](slide_files/figure-html/unnamed-chunk-8-1.svg){fig-align='center' width=90%}\n:::\n:::\n\n\nAs we can see from the center top panel, it looks like Florida moved to weekly \nreporting of COVID-19 cases in summer of 2021, while California occasionally reported negative cases counts!\n\n## Running a local forecaster {#sec-local-forecaster}\n\nAs a more complex example, we preview some of the functionality of `{epipredict}` described in future chapters, and use a forecaster based on a\nlocal (in time)\nautoregression or \"AR model\". AR models can be fit in numerous ways \n(using base R\nfunctions and various packages), but here we the `arx_forecaster()`, implemented in `{epipredict}` both\nprovides a more advanced example of sliding a function over an `epi_df` object,\nand it allows us to be a bit more flexible in defining a *probabilistic*\nforecaster: one that outputs not just a point prediction, but a notion of\nuncertainty around this. In particular, our forecaster will output a point\nprediction along with an 90\\% uncertainty band, represented by a predictive\nquantiles at the 5\\% and 95\\% levels (lower and upper endpoints of the\nuncertainty band).\n\nThe function signature below, is a probabilistic AR forecaster. The\n`lags` argument indicates which lags to use in the model, and `ahead` indicates\nhow far ahead in the future to make forecasts (both are encoded in terms of the\nunits of the `time_value` column; so, days, in the working `epi_df` being\nconsidered in this vignette).\n\n\n::: {.cell layout-align=\"center\" hash='slide_cache/html/unnamed-chunk-9_079e5420d9e5d2f5501eb74de8b45cb6'}\n\n```{.r .cell-code}\narx_forecaster <- function(\n    epi_df, \n    outcome, # the outcome column name in `epi_df`\n    predictors, # a character vector, containing 1 or more predictors in `epi_df`\n    trainer = quantile_reg(), \n    args_list = arx_args_list(\n      lags = c(0, 7, 14), \n      ahead = 7,\n      quantile_levels = c(0.05, 0.95)\n    )\n)\n```\n:::\n\n\nWe go ahead and slide this AR forecaster over the working `epi_df` of COVID-19 \ncases. Note that we actually model the `cases_7dav` column, to operate on the \nscale of smoothed COVID-19 cases. This is clearly equivalent, up to a constant,\nto modeling weekly sums of COVID-19 cases.\n\n\n::: {.cell layout-align=\"center\" hash='slide_cache/html/unnamed-chunk-10_9e2bba94dc13dd185ad30b365f0a4eb4'}\n\n```{.r .cell-code}\nfc_time_values <- seq(\n  from = as.Date(\"2020-06-01\"),\n  to = as.Date(\"2021-12-01\"),\n  by = \"1 months\"\n)\n\nfcasts <- epi_slide(\n  x,\n  ~ arx_forecaster(\n    epi_data = .x,\n    outcome = \"cases_7dav\",\n    predictors = \"cases_7dav\",\n    trainer = quantile_reg(),\n    args_list = arx_args_list(ahead = 7)\n  )$predictions,\n  before = 119,\n  ref_time_values = fc_time_values,\n  new_col_name = \"fc\"\n)\n\n# grab just the relevant columns, and make them easier to plot\nfcasts <- fcasts %>%\n  select(\n    geo_value, time_value, cases_7dav,\n    contains(\"_distn\"), fc_target_date\n  ) %>%\n  pivot_quantiles_wider(contains(\"_distn\"))\nfcasts\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> # A tibble: 114 × 7\n#>   geo_value time_value cases_7dav fc_target_date `0.05` `0.5` `0.95`\n#>   <chr>     <date>          <dbl> <date>          <dbl> <dbl>  <dbl>\n#> 1 ca        2020-06-01      2655. 2020-06-08      1940. 2694.  3840.\n#> 2 fl        2020-06-01       726. 2020-06-08       558.  747.  1290.\n#> 3 ga        2020-06-01       643. 2020-06-08       520.  638.  1083.\n#> 4 ny        2020-06-01      1278. 2020-06-08       821. 1044.  1864.\n#> 5 pa        2020-06-01       603. 2020-06-08       450.  570.  1080.\n#> 6 tx        2020-06-01      1002. 2020-06-08       716. 1134.  1950.\n#> # ℹ 108 more rows\n```\n:::\n:::\n\n\nNote that here we have used an argument `ref_time_values` to perform the\nsliding computation (here, compute a forecast) at a specific subset of reference\ntime values. We get out 4 new columns: `fc_target_date`, `0.05`, `0.5`, `0.95`\nthat correspond to the date the forecast is for (rather than the date it was made on, the point forecast, and the lower and upper endpoints of the\n95\\% prediction band.[^1]\n\n[^1]: If instead we had set `as_list_col = TRUE`\nin the call to `epi_slide()`, then we would have gotten a list column `fc`, \nwhere each element of `fc` contains these results.\n\nTo finish off, we plot the forecasts at some times (spaced out by a few months)\nover the last year, at multiple horizons: 7, 14, 21, and 28 days ahead. To do \nso, we encapsulate the process of generating forecasts into a simple function, \nso that we can call it a few times.\n\n\n::: {.cell layout-align=\"center\" hash='slide_cache/html/unnamed-chunk-11_d30fdf1ff99b2e470d215f81656d5b01'}\n\n```{.r .cell-code}\nk_week_ahead <- function(ahead = 7) {\n  epi_slide(\n    x,\n    ~ arx_forecaster(\n      epi_data = .x,\n      outcome = \"cases_7dav\",\n      predictors = \"cases_7dav\",\n      trainer = quantile_reg(),\n      args_list = arx_args_list(ahead = ahead)\n    )$predictions,\n    before = 119,\n    ref_time_values = fc_time_values,\n    new_col_name = \"fc\"\n  ) %>%\n    select(\n      geo_value, time_value, cases_7dav, contains(\"_distn\"),\n      fc_target_date\n    ) %>%\n    pivot_quantiles_wider(contains(\"_distn\"))\n}\n\n# First generate the forecasts, and bind them together\nz <- map(c(7, 14, 21, 28), k_week_ahead) %>% list_rbind()\n```\n:::\n\n\nThen we can plot the on top of the observed data\n\n::: {.cell layout-align=\"center\" hash='slide_cache/html/unnamed-chunk-12_f17b1e21df0fa2849ed240533f7e168f'}\n\n```{.r .cell-code  code-fold=\"true\"}\nggplot(z) +\n  geom_line(data = x, aes(x = time_value, y = cases_7dav), color = \"gray50\") +\n  geom_ribbon(aes(\n    x = fc_target_date, ymin = `0.05`, ymax = `0.95`,\n    group = time_value, fill = geo_value\n  ), alpha = 0.4) +\n  geom_line(aes(x = fc_target_date, y = `0.5`, group = time_value)) +\n  geom_point(aes(x = fc_target_date, y = `0.5`, group = time_value), size = 0.5) +\n  # geom_vline(data = tibble(x = fc_time_values), aes(xintercept = x),\n  #           linetype = 2, alpha = 0.5) +\n  facet_wrap(vars(geo_value), scales = \"free_y\", nrow = 3) +\n  scale_y_continuous(expand = expansion(c(0, 0.05))) +\n  scale_x_date(minor_breaks = \"1 months\", date_labels = \"%b %Y\") +\n  scale_fill_viridis_d(guide = \"none\", end = .9) +\n  labs(x = \"Date\", y = \"Reported COVID-19 cases\")\n```\n\n::: {.cell-output-display}\n![](slide_files/figure-html/unnamed-chunk-12-1.svg){fig-align='center' width=90%}\n:::\n:::\n\n\nTwo points are worth making. First, the AR model's performance here is pretty\nspotty. At various points in time, we can see that its forecasts are volatile\n(its point predictions are all over the place), or overconfident (its bands are\ntoo narrow), or both at the same time. This is only meant as a simple demo and\nnot entirely unexpected given the way the AR model is set up. The\n[`epipredict`](https://cmu-delphi.github.io/epipredict) package, \noffers a suite of predictive modeling tools \nthat improve on many of the shortcomings of the above simple AR model (simply \nusing all states for training rather than 6 is a huge improvement).\n\nSecond, the AR forecaster here is using finalized data, meaning, it uses the\nlatest versions of signal values (reported COVID-19 cases) available, for both\ntraining models and making predictions historically. However, this is not\nreflective of the provisional nature of the data that it must cope with in a\ntrue forecast task. Training and making predictions on finalized data can lead\nto an overly optimistic sense of accuracy; see, for example, \n[@McDonaldBien2021] and references\ntherein. Fortunately, the `epiprocess` package provides a data structure called\n`epi_archive` that can be used to store all data revisions, and furthermore, an\n`epi_archive` object knows how to slide computations in the correct\nversion-aware sense (for the computation at each reference time $t$, it uses\nonly data that would have been available as of $t$). We will revisit this \nexample in the [archive \nvignette](https://cmu-delphi.github.io/epiprocess/articles/archive.html).\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}